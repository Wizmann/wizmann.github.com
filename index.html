<!doctype html><html><head><meta name=generator content="Hugo 0.146.0"><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]]},svg:{fontCache:"global"}}</script><script defer src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><header class=header-wrapper><div class=header><a class=site-title href=https://wizmann.top/>Maerlyn's Rainbow</a><nav class=menu></nav></div></header><main class=main-wrapper><div class=main><div class=max-wrapper><div id=list-page><section class=list-item><h1 class=title><a href=/posts/why-not-start-with-ddia-part-1/>为什么我不建议你阅读《数据密集型应用系统设计》（之一）</a></h1><div class=tips><div class=date><time datetime="2025-05-17 00:00:00 +0000 UTC">2025/05/17</time></div><div class=tags><span>Tags:</span>
<a href=/tags/%E6%95%B0%E6%8D%AE%E5%BA%93>数据库</a>
<a href=/tags/%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F>数据系统</a>
<a href=/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F>分布式系统</a>
<a href=/tags/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F>数据密集型应用系统</a>
<a href=/tags/%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B>数据模型</a></div></div><div class=summary><p><strong>因为我是标题党。</strong></p><p>这本书与我们常用来垫显示器的《算法导论》或《深入理解计算机系统》（如果你是大一大二的同学，可能还包括《算法竞赛入门经典》）并不属于同一类。它更接近《C++ Primer》或那本《算法》(Robert Sedgewick 著）——属于通识型读物。</p></div></section><section class=list-item><h1 class=title><a href=/posts/press-pad-3d-model/>3D打印解压玩具 / 3D Printed Fidget Toy</a></h1><div class=tips><div class=date><time datetime="2025-04-05 00:00:00 +0000 UTC">2025/04/05</time></div><div class=tags><span>Tags:</span>
<a href=/tags/3d-printing>3D printing</a></div></div><div class=summary><p>这是一款我用3D打印制作的小巧解压玩具，造型为柔和的三角形，中间布满可以按压的小圆点，简单又有趣。适合在工作或学习时用来放松，也适合小朋友玩耍。</p></div></section><section class=list-item><h1 class=title><a href=/posts/vertical-axis-wind-turbine-3d-model/>风力涡轮机 3D 模型 / Vertical Axis Wind Turbine (VAWT) 3D Model</a></h1><div class=tips><div class=date><time datetime="2025-04-05 00:00:00 +0000 UTC">2025/04/05</time></div><div class=tags><span>Tags:</span>
<a href=/tags/3d-printing>3D printing</a></div></div><div class=summary><p>这是一款垂直轴风力涡轮机（VAWT）3D模型，外观采用螺旋扭转的叶片设计，具有极强的美感和结构对称性。它不需要支撑结构，方便3D打印，同时底部设计了一个标准的608轴承接口，用于展示旋转效果。需要注意的是，它并非真正的风力驱动设备，仅为一个展示用模型。</p></div></section><section class=list-item><h1 class=title><a href=/posts/lava-store/>论文阅读：LavaStore - 高性能、本地存储引擎的演进</a></h1><div class=tips><div class=date><time datetime="2025-02-17 00:00:00 +0000 UTC">2025/02/17</time></div><div class=tags><span>Tags:</span>
<a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB>论文阅读</a>
<a href=/tags/lavastore>LavaStore</a>
<a href=/tags/rocksdb>RocksDB</a></div></div><div class=summary><h2 id=引言>引言 <a href=#%e5%bc%95%e8%a8%80 class=anchor>🔗</a></h2><p>在云服务的快速发展中，持久化键值（KV）存储引擎的性能和成本效率成为了关键挑战。字节跳动（ByteDance）在其大规模云服务中广泛使用 RocksDB 作为本地存储引擎。然而，由于 RocksDB 在高写入密集型负载、成本优化以及尾延迟控制上的局限性，字节跳动团队开发了 <strong>LavaStore</strong>，一个专门针对云服务优化的高性能、本地存储引擎。</p></div></section><section class=list-item><h1 class=title><a href=/posts/std-smart-ptrs-cpp-for-the-antiquated-4/>动手实现智能指针 （上篇） - C++ for the Antiquated（之四）</a></h1><div class=tips><div class=date><time datetime="2025-01-21 00:00:00 +0000 UTC">2025/01/21</time></div><div class=tags><span>Tags:</span>
<a href=/tags/cpp>cpp</a>
<a href=/tags/modern-cpp>modern cpp</a></div></div><div class=summary><p>智能指针（如 <code>std::shared_ptr</code> 和 <code>std::weak_ptr</code>）已经成为现代 C++ 编程的重要工具，尽管它们并不算是“新兴”的特性。在 C++11 标准之前，Boost 库就已经引入了智能指针的实现，特别是 <code>boost::shared_ptr</code> 和 <code>boost::weak_ptr</code>，它们为 C++11 的智能指针特性奠定了基础。因此，可以说智能指针在 C++ 中的发展历程已经有很长时间，而它们的引入极大地简化了内存管理和避免了常见的内存泄漏和悬挂指针问题。</p></div></section><section class=list-item><h1 class=title><a href=/posts/std-visit-polymorphism-cpp-for-the-antiquated-3/>std::visit实现运行时多态 - C++ for the Antiquated（之三）</a></h1><div class=tips><div class=date><time datetime="2025-01-04 00:00:00 +0000 UTC">2025/01/04</time></div><div class=tags><span>Tags:</span>
<a href=/tags/cpp>cpp</a>
<a href=/tags/modern-cpp>modern cpp</a></div></div><div class=summary><p>在传统的 <strong>C++</strong> 中，<strong>运行时多态</strong> 通常依赖于 <strong>“接口 - 虚函数”</strong> 机制，通过抽象类、具体类与对象的设计来实现。这种多态方式通常被称为 <strong>子类型多态</strong>（<em>Subtype Polymorphism</em>）。</p></div></section><section class=list-item><h1 class=title><a href=/posts/std-visit-cpp-for-the-antiquated-2/>动手实现std::visit - C++ for the Antiquated（之二）</a></h1><div class=tips><div class=date><time datetime="2025-01-01 00:00:00 +0000 UTC">2025/01/01</time></div><div class=tags><span>Tags:</span>
<a href=/tags/cpp>cpp</a>
<a href=/tags/modern-cpp>modern cpp</a></div></div><div class=summary><h2 id=stdvariant-与-stdvisit>std::variant 与 std::visit <a href=#stdvariant-%e4%b8%8e-stdvisit class=anchor>🔗</a></h2><h3 id=stdvariant>std::variant <a href=#stdvariant class=anchor>🔗</a></h3><p><code>std::variant</code> 是 C++17 引入的类型安全的联合体（type-safe union），可以在多个预定义类型中存储任意一个值。与传统的 <code>union</code> 不同，<code>std::variant</code> 能够在运行时安全地检查当前存储的类型，避免未定义行为。</p></div></section><section class=list-item><h1 class=title><a href=/posts/constexpr-cpp-for-the-antiquated-1/>constexpr详解 - C++ for the Antiquated（之一）</a></h1><div class=tips><div class=date><time datetime="2024-12-28 00:00:00 +0000 UTC">2024/12/28</time></div><div class=tags><span>Tags:</span>
<a href=/tags/cpp>cpp</a>
<a href=/tags/modern-cpp>modern cpp</a></div></div><div class=summary><p>在这篇文章中，我们将深入讨论 C++ 中的常量表达式（<code>constexpr</code>）及其与传统的<code>const</code>常量的区别，并结合实际代码示例进行说明。同时，我们还会探讨<code>constexpr</code>函数在模板编程中的应用，以及 C++11 之后对常量表达式的优化与扩展。</p></div></section><section class=list-item><h1 class=title><a href=/posts/cache-coherence-and-memory-order-2/>CPU缓存一致性与内存一致性（第二部分-内存一致性）</a></h1><div class=tips><div class=date><time datetime="2024-09-01 00:24:00 +0000 UTC">2024/09/01</time></div><div class=tags><span>Tags:</span>
<a href=/tags/cpp>cpp</a>
<a href=/tags/memory-barrier>memory-barrier</a>
<a href=/tags/multithread>multithread</a>
<a href=/tags/litmus>litmus</a>
<a href=/tags/herd7>herd7</a></div></div><div class=summary><h2 id=缓存一致性与内存一致性>缓存一致性与内存一致性 <a href=#%e7%bc%93%e5%ad%98%e4%b8%80%e8%87%b4%e6%80%a7%e4%b8%8e%e5%86%85%e5%ad%98%e4%b8%80%e8%87%b4%e6%80%a7 class=anchor>🔗</a></h2><p>缓存一致性和内存一致性是多处理器系统中的两个不同概念，它们解决的是不同类型的内存访问问题。</p><p>缓存一致性协议（如 MESI 协议）用于解决多个处理器对相同内存位置进行访问和修改时的数据一致性问题。它确保各处理器的缓存中针对同一内存地址的副本保持一致，避免因缓存不同步而导致的数据错误。</p></div></section><section class=list-item><h1 class=title><a href=/posts/atcoder-abc356g-solution/>利用凸组合求解最优值（AtCoder abc356_g Freestyle 题解）</a></h1><div class=tips><div class=date><time datetime="2024-06-15 00:00:00 +0000 UTC">2024/06/15</time></div><div class=tags><span>Tags:</span>
<a href=/tags/atcoder>AtCoder</a>
<a href=/tags/solution>Solution</a>
<a href=/tags/computational-geometry>Computational geometry</a>
<a href=/tags/geometry>geometry</a></div></div><div class=summary><ul><li><h2 id=题目大意>题目大意 <a href=#%e9%a2%98%e7%9b%ae%e5%a4%a7%e6%84%8f class=anchor>🔗</a></h2><ul><li>我们已经学会了 <strong>N</strong> 种不同的游泳技术。对于每种技术 $i$ ，每秒前进 $A_{i}$ 米，并消耗 $B_{i}$ 单位的体力。注意，我们可以任意调整每种技术的使用时长 $t_i$ ，其中 $t_i$ 是一个实数</li><li>现在，我们面临 $Q$ 次询问，每次询问指定距离终点的距离 $C_j$ 和体力限制 $D_j$ 。我们需要确定是否在体力限制下到达终点。如果可以，求出所需的最短时间。</li><li>（符号使用与原题略有差异）</li><li><strong>数据规模</strong>：<ul><li>$1 &lt;= N, Q &lt;= 2 \times 10^5$</li><li>$1 &lt;= A_i, B_i, C_j, D_j &lt;= 10^9$</li></ul></li></ul></li><li><h2 id=题目分析>题目分析 <a href=#%e9%a2%98%e7%9b%ae%e5%88%86%e6%9e%90 class=anchor>🔗</a></h2><ul><li>鉴于数据规模庞大，并且时间 $t_i$ 是实数，传统的动态规划方法不适用。在处理每次询问时，我们需要同时考虑距离、体力和时间三个变量。一个有效的方法是转化这些变量为单位时间内的距离（即速度）和单位时间内的体力消耗。如果单位时间内的距离大于单位时间内的体力消耗，那么理论上我们可以到达终点。接下来的目标是在所有可能的情况中找到最大的速度，作为最终答案。
以两种游泳技术（N=2）为例进行具体分析。假设在总游泳时间中，技术1和技术2的使用时间比例分别为 $p$ 和 $1-p$ （其中 $0 \leq p \leq 1$ ）。在这种情况下，每秒前进距离为 $A_1 \cdot p + A_2 \cdot (1 - p)$ ，体力消耗为 $B_1 \cdot p + B_2 \cdot (1 - p)$ 。<br>从几何角度看，组合这两种游泳技术的速度与体力消耗 $(A_x, B_x)$ 为 $(A_1, B_1) \cdot p$ 和 $(A_2, B_2) \cdot (1 - p)$ 的向量和，其可能的取值位于以 $(A_1, B_1)$ 和 $(A_2, B_2)$ 为端点的线段上的任意一点。<br>对于具体询问 $(C_i, D_i)$ ，为了确保“在到达终点之前不能耗尽体力”，我们需要找到的点必须位于斜率为 $D_i/C_i$ 的射线与x轴之间的夹角内。通过这种方式，我们可以确定是否有可能在给定的体力限制下完成指定的距离，并找到速度最快的点。</li><li><img src=https://raw.githubusercontent.com/Wizmann/assets/965294986c47c3153fe9cd4e831748903ba224ef/wizmann-pic/24-06-15/%E4%B8%8B%E8%BD%BD_1718003803558_0.png alt=下载_1718003803558_0.png></li><li>对于多种游泳技术的组合，情况会更复杂一些。我们将所有游泳技术视为一组向量 $(A_1, B_1), (A_2, B_2), \ldots, (A_n, B_n)$ 和一组对应的权重 $p_1, p_2, \ldots, p_n$ ，其中 $\sum_{i=1}^n p_i = 1$ 并且每个 $p_i \geq 0$ ，那么这些向量的加权和 $\sum_{i=1}^n p_i (A_i, B_i)$ 定义了一个在二维空间中的凸多边形，称为这些向量的凸包。</li><li>我们可以用稍微详细一点的数学来解释这一过程：<ul><li><h3 id=向量的线性组合>向量的线性组合 <a href=#%e5%90%91%e9%87%8f%e7%9a%84%e7%ba%bf%e6%80%a7%e7%bb%84%e5%90%88 class=anchor>🔗</a></h3><ul><li>首先，定义向量 $\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_n$ 在二维空间中的位置。每个向量 $\mathbf{v}<em>i$ 可以表示为从原点到点 $(x_i, y_i)$ 的箭头。
当我们考虑这些向量的线性组合时： $\sum</em>{i=1}^n \lambda_i \mathbf{v}_i$<br>其中，每个 $\lambda_i$ 是一个实数系数，我们实际上在描述一个新向量，这个向量是通过在每个原向量上“拉伸”或“压缩”（取决于 $\lambda_i$ 的正负和大小），然后将结果相加得到的。这种线性组合在几何上定义了一个点的集合。</li></ul></li><li><h3 id=凸组合与凸多边形>凸组合与凸多边形 <a href=#%e5%87%b8%e7%bb%84%e5%90%88%e4%b8%8e%e5%87%b8%e5%a4%9a%e8%be%b9%e5%bd%a2 class=anchor>🔗</a></h3><ul><li>当这些系数 $\lambda_i$ 都非负且和为1（即 $\lambda_i \geq 0$ 且 $\sum_{i=1}^n \lambda_i = 1$ ），我们称这样的线性组合为<strong>凸组合</strong>。凸组合具有重要的几何特性：它定义的点一定位于这些向量端点所形成的凸多边形内部或边界上。</li></ul></li><li><h3 id=凸多边形的形成>凸多边形的形成 <a href=#%e5%87%b8%e5%a4%9a%e8%be%b9%e5%bd%a2%e7%9a%84%e5%bd%a2%e6%88%90 class=anchor>🔗</a></h3><ul><li><ol><li><strong>边界的构成</strong>：如果你只考虑两个向量 $\mathbf{v}_1$ 和 $\mathbf{v}_2$ ，那么它们的凸组合会形成一条连接两点 $(x_1, y_1)$ 和 $(x_2, y_2)$ 的线段。这条线段是直线，因为所有的组合点都直接通过两点间的直线路径互相连结。</li></ol></li><li><ol start=2><li><strong>扩展到多个向量</strong>：当你有三个或更多向量时，通过考虑任意两个向量的所有凸组合（即所有可能的线段），然后再将这些线段的结果进行组合，最终你将覆盖一个多边形区域。这个区域是由最外围的向量点定义的，这些点在几何上构成了凸多边形的顶点。</li></ol></li><li><ol start=3><li><strong>数学描述</strong>：在数学上，这个区域可以看作是所有可能的 $\lambda_i$ 值（符合凸组合条件）下的 $\sum_{i=1}^n \lambda_i \mathbf{v}_i$ 的集合。由于每个 $\lambda_i$ 都保证非负且和为1，凸多边形的任意内部或边界点都可以通过这样的组合表示，且不会有任何点“凸出”于这个定义的多边形之外，这正是凸性质的体现。</li></ol></li></ul></li></ul></li><li>类似于仅涉及两个点的简单情况，为了解决问题，我们需要找到凸多边形内与 $x$ 轴之间斜率为 $D_i/C_i$ 的射线包围的区域（即凸包中的深色部分）。我们进一步需要找出该部分中在 $x$ 轴上取得最大值的点。</li><li><img src=https://raw.githubusercontent.com/Wizmann/assets/965294986c47c3153fe9cd4e831748903ba224ef/wizmann-pic/24-06-15/geogebra-export_1718034870873_0.png alt=geogebra-export.png></li></ul></li><li><h2 id=代码实现---并不高效>代码实现 - 并不高效 <a href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0---%e5%b9%b6%e4%b8%8d%e9%ab%98%e6%95%88 class=anchor>🔗</a></h2><ul><li><h3 id=实现步骤>实现步骤 <a href=#%e5%ae%9e%e7%8e%b0%e6%ad%a5%e9%aa%a4 class=anchor>🔗</a></h3><ul><li>求出所有 $(A_i, B_i)$ 点所构成的凸包</li><li>对于每一个查询Q，从零点画出斜率为 $D_i / C_i$ 的射线</li><li>如果凸包位于射线的“上方”，则没有满足条件的情况，返回-1</li><li>如果凸包位于射线的“下方”或与射线相交，则需要找到凸包在射线“下方” $B_i$ 值最大的点。意味着这个组合可以成功到达终点，并且平均速度最快</li></ul></li><li><h3 id=复杂度分析>复杂度分析 <a href=#%e5%a4%8d%e6%9d%82%e5%ba%a6%e5%88%86%e6%9e%90 class=anchor>🔗</a></h3><ul><li>对于每一次查询，我们都要遍历凸包的所有边（即“凸包壳”）与射线的交点。时间复杂度 $O(n)$ 。</li><li>对于所有查询，时间复杂度为 $O(q * n)$ ，明显是会超时的。</li></ul></li></ul></li><li><h2 id=优化的可能性>优化的可能性 <a href=#%e4%bc%98%e5%8c%96%e7%9a%84%e5%8f%af%e8%83%bd%e6%80%a7 class=anchor>🔗</a></h2><ul><li>易知，并不是凸包的所有部分都能得出最优解。与原点连线斜率越小的点，其“性价比”越高，即在消耗更少的体力的同时，可以游更远的距离。
同时，如果凸包内部的某一个点满足条件，则总有位于凸包壳上面的另一个点与它更优。同样，如果凸包壳上有两个点的斜率相同，那么 $B_i$ 值更大的点是更优的。<br>所以优化的目标在于找到一系列凸包壳，使其可以只保留最优解所在的边，并且排除所有非最优的情况。<br>我们可以从“性价比”最好的点开始，因为对于一个查询，如果所需要的“性价比”高于我们所有的选项，那么一定没有解。<br>然后我们逆时针遍历所有点，直到找到 $B_i$ 值最大的点，因为对于一个查询，在满足“性价比”的情况下，这是我们能给出的，消耗时间最小的答案。</li><li><h3 id=实现方案1>实现方案1: <a href=#%e5%ae%9e%e7%8e%b0%e6%96%b9%e6%a1%881 class=anchor>🔗</a></h3><ul><li>我们可以使用凸包算法，找到凸包壳，按照上文所述的方法，找到斜率最小（所谓“性价比最高”）的点，然后逆时针遍历到 $B_i$ 最大的点。这些点必然以斜率从小到大排序。
对于一个查询 $(C_i, D_i)$ ，我们将其视为斜率为 $D_i / C_i$ 的射线。我们使用二分法，找到与该射线相交的凸包壳边。再通过联立方程方法找到其交点 $(A_x, B_x)$ ，其中 $A_x$ 即为满足查询条件的最大游泳速度。</li></ul></li><li><h3 id=实现方案2>实现方案2： <a href=#%e5%ae%9e%e7%8e%b0%e6%96%b9%e6%a1%882 class=anchor>🔗</a></h3><ul><li>方案2与方案1类似，只是在查找凸包的时候，加入点 $(0, 0)$ 与点 $(max(A_i), INF)$ 。如下图所示，加入这两个点之后，非最优解的点都被包含在了凸包（蓝色）内部。我们在找到凸包之后，将加入的点删除，并按方案1的方法排序。后续再进行二分，以及求交点等操作。</li><li><img src=https://raw.githubusercontent.com/Wizmann/assets/965294986c47c3153fe9cd4e831748903ba224ef/wizmann-pic/24-06-15/image_1718464319087_0.png alt=image.png></li></ul></li></ul></li><li><h2 id=代码实现>代码实现 <a href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0 class=anchor>🔗</a></h2><ul><li><a href=https://atcoder.jp/contests/abc356/submissions/54463383>我写的</a> （抄了别人的凸包算法）</li><li><a href=https://atcoder.jp/contests/abc356/editorial/10145>官方题解</a></li></ul></li><li><h2 id=感悟>感悟 <a href=#%e6%84%9f%e6%82%9f class=anchor>🔗</a></h2><ul><li>别调计算几何，会变的不幸（</li></ul></li></ul></div></section><section class=list-item><h1 class=title><a href=/posts/implement-non-blocking-queue-2/>实现一个无锁消息队列（续与勘误）</a></h1><div class=tips><div class=date><time datetime="2024-04-14 00:00:00 +0000 UTC">2024/04/14</time></div><div class=tags><span>Tags:</span>
<a href=/tags/multi-thread>multi-thread</a>
<a href=/tags/cas>cas</a>
<a href=/tags/cmpxchg>cmpxchg</a>
<a href=/tags/non-blocking>non-blocking</a>
<a href=/tags/wait-free>wait-free</a></div></div><div class=summary><ul><li>本文内容主要参考自<a href=https://people.cs.pitt.edu/~jacklange/teaching/cs2510-f17/implementing_lock_free.pdf>Implementing Lock-Free Queue</a>一文（以下简称“原论文”）</li><li>是对<a href=https://wizmann.top/implement-non-blocking-queue.html>实现一个无锁消息队列</a>一文的内容进行补充</li><li><h2 id=tldr>TL；DR <a href=#tldr class=anchor>🔗</a></h2><ul><li>尽管<a href=https://wizmann.top/implement-non-blocking-queue.html>实现一个无锁消息队列</a>一文中的实现是正确的，但是忽略了“非阻塞性”<ul><li>例如，当任一插入操作被阻塞，则其它插入操作均会陷入忙等待</li><li>此实现与<a href=https://dl.acm.org/doi/pdf/10.5555/110382.110466>A simple and correct shared-queue algorithm using Compare-and-Swap</a>的实现基本一致</li></ul></li><li>对于一个支持并发的数据结构，理应同时具备非阻塞性和无等待性<ul><li>非阻塞性（non-blocking）：无论是由于CPU调度或其他外部因素，数据结构的操作不能被中断或延迟</li><li>无等待性（wait-free)：保证没有任何线程会遭受饥饿状态</li></ul></li><li>前一篇博文对其它实现的质疑，主要在于ABA问题，但这个问题是Compare&amp;Swap所特有的，需要特定的实现来规避</li></ul></li><li><h2 id=理论基础>理论基础 <a href=#%e7%90%86%e8%ae%ba%e5%9f%ba%e7%a1%80 class=anchor>🔗</a></h2><ul><li>我们的目标是实现一个支持并发enqueue/deque的队列</li><li>对于这样的数据结构，有两个重要的特性<ul><li>非阻塞性（non-blocking）<ul><li>对于每一个执行线程，所有的操作将会在有限的次数内完成</li><li>无论本线程或其它线程在执行过程中因其它原因（如CPU调度）执行过缓，或者被中断</li></ul></li><li>无等待性（wait-free)<ul><li>没有线程会饥饿</li></ul></li><li>基于锁的数据结构不符合上述特性，因为持有锁的线程可能会无限期地阻塞所有操作</li><li>“线性一致性”(Linearizability) —— 更强的正确性<ul><li>非并发操作应当按照它们的逻辑顺序执行，以保证操作的正确性，而并发操作则可以按任意顺序进行</li></ul></li></ul></li><li>&ldquo;Fetch&amp;Add&rdquo; 与 &ldquo;Compare&amp;Swap&rdquo;<ul><li>常用的原子操作，这里不做赘述</li></ul></li></ul></li><li><h2 id=基于链表的无锁队列实现>基于链表的无锁队列实现 <a href=#%e5%9f%ba%e4%ba%8e%e9%93%be%e8%a1%a8%e7%9a%84%e6%97%a0%e9%94%81%e9%98%9f%e5%88%97%e5%ae%9e%e7%8e%b0 class=anchor>🔗</a></h2><ul><li>略，参考原论文与<a href=https://coolshell.cn/articles/8239.html>无锁队列的实现</a>一文</li></ul></li><li><h2 id=基于数组的无锁队列实现>基于数组的无锁队列实现 <a href=#%e5%9f%ba%e4%ba%8e%e6%95%b0%e7%bb%84%e7%9a%84%e6%97%a0%e9%94%81%e9%98%9f%e5%88%97%e5%ae%9e%e7%8e%b0 class=anchor>🔗</a></h2><ul><li>略，参考原论文与<a href=https://coolshell.cn/articles/8239.html>无锁队列的实现</a>一文</li></ul></li><li><h2 id=aba问题>ABA问题 <a href=#aba%e9%97%ae%e9%a2%98 class=anchor>🔗</a></h2><ul><li>Compare&amp;Swap操作确保了值修改的原子性。指针作为值的一种，代表着某个内存地址，但Compare&amp;Swap对指针的操作无法保证其指向的内存内容不被修改</li><li>考虑到可能释放旧内存后再申请新内存，这两块内存虽逻辑不同却可能拥有同一地址，这对Compare&amp;Swap操作造成了困扰</li><li>解决方案是为指针加入引用计数（ref count），以确保内存在可访问时不会被释放或重用</li></ul></li><li><h2 id=性能对比>性能对比 <a href=#%e6%80%a7%e8%83%bd%e5%af%b9%e6%af%94 class=anchor>🔗</a></h2><ul><li>上面我们已经提到，<a href=https://dl.acm.org/doi/pdf/10.5555/110382.110466>A simple and correct shared-queue algorithm using Compare-and-Swap</a>一文中的方法缺少了“非阻塞性”，，但其性能与原论文中的实现十分接近</li><li>但是在原理上，“非阻塞性”实现可以避免意外的线程停止或延迟</li><li>疑问：是否会在P99级别的Latency上才会体现出明显的差异？</li></ul></li><li><h2 id=参考链接>参考链接 <a href=#%e5%8f%82%e8%80%83%e9%93%be%e6%8e%a5 class=anchor>🔗</a></h2><ul><li><a href=https://people.cs.pitt.edu/~jacklange/teaching/cs2510-f17/implementing_lock_free.pdf>Implementing Lock-Free Queue</a></li><li><a href=https://dl.acm.org/doi/pdf/10.5555/110382.110466>A simple and correct shared-queue algorithm using Compare-and-Swap</a></li><li><a href=https://cs.nyu.edu/~wies/teaching/cso-fa19/class27_concurrency.pdf>Concurrency – Correctness of Concurrent Objects</a></li></ul></li><li><h2 id=后续>后续 <a href=#%e5%90%8e%e7%bb%ad class=anchor>🔗</a></h2><ul><li><a href=https://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf>Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms</a></li><li><a href=https://zhuanlan.zhihu.com/p/690872647>C++ 单生产者&单消费者 无锁队列</a></li><li><a href="https://www.youtube.com/watch?v=K3P_Lmq6pw0&amp;ab_channel=CppCon">Single Producer Single Consumer Lock-free FIFO From the Ground Up - Charles Frasch - CppCon 2023</a></li></ul></li></ul><div class="alert alert-info" role=alert>本文大（划掉）部分内容由ChatGPT4生成</div></div></section><section class=list-item><h1 class=title><a href=/posts/cache-coherence-and-memory-order/>CPU缓存一致性与内存一致性（第一部分-MESI协议）</a></h1><div class=tips><div class=date><time datetime="2024-03-18 23:21:35 +0000 UTC">2024/03/18</time></div><div class=tags><span>Tags:</span>
<a href=/tags/cpp>cpp</a>
<a href=/tags/memory-barrier>memory-barrier</a>
<a href=/tags/multithread>multithread</a>
<a href=/tags/thread>thread</a>
<a href=/tags/mesi>MESI</a></div></div><div class=summary><p>在对称多处理系统（Symmetric Multiprocessing, SMP）中，一个变量（或内存位置）可以同时存在于多个CPU的缓存行中。为了提供完美的用户级抽象，任何对一个或多个变量的修改都应该被强制同步，以确保其它CPU的缓存得到更新。
然而，在实现上，由于CPU之间通常通过总线互联，它们不能同时对多个缓存进行写操作。</p></div></section><section class=list-item><h1 class=title><a href=/posts/tl-dr-borg/>[tl;dr] 论文阅读：Borg - Large-scale cluster management at Google</a></h1><div class=tips><div class=date><time datetime="2023-12-27 00:00:00 +0000 UTC">2023/12/27</time></div><div class=tags><span>Tags:</span>
<a href=/tags/borg>Borg</a>
<a href=/tags/distributed-system>Distributed System</a>
<a href=/tags/kubernetes>Kubernetes</a>
<a href=/tags/google>Google</a></div></div><div class=summary><ul><li><h2 id=系统概览>系统概览 <a href=#%e7%b3%bb%e7%bb%9f%e6%a6%82%e8%a7%88 class=anchor>🔗</a></h2><ul><li>Borg是谷歌开发的一种高效的集群管理系统，旨在优化资源利用率和提高系统的可靠性及可用性<ul><li>隐藏资源管理细节与故障处理，允许用户专注于应用程序的开发</li><li>保证非常高的可靠性和可用性，以支持用户应用程序的高可靠性和高可用性</li><li>支持运行来自众多应用的数十万个作业，并高效运行于数以万计的机器上</li></ul></li></ul></li><li><h2 id=用户视角>用户视角 <a href=#%e7%94%a8%e6%88%b7%e8%a7%86%e8%a7%92 class=anchor>🔗</a></h2><ul><li>用户通过定义<em>job</em>和<em>task</em>与Borg进行交互<ul><li>一个<em>job</em>由运行相同程序的一个或多个<em>task</em>组成</li><li>每一个<em>job</em>运行于一个<em>Borg cell</em>（单元）之中，<em>cell</em>是一组机器的集合，是Borg管理的基本单元</li></ul></li><li>Borg的工作负载<ul><li>长期运行的时延敏感型服务</li><li>批处理作业</li><li>运行在实体机上，避免VM的虚拟化开销</li></ul></li><li><em>Allocs</em><ul><li>预留给一项或多项任务的一组资源</li><li><em>Alloc</em>可以将不同 <em>jobs</em> 的 <em>tasks</em> 聚集到同一台机器上</li><li>如果一个 <em>alloc</em> 必须重新分配到另外一台主机，属于它的 <em>task(s)</em> 也会同它一起重新被调度</li><li>一旦创建一个 <em>alloc</em> 集合，就可以提交一个或多个 jobs 运行其中</li></ul></li><li>命名服务和监控<ul><li>Borg包含一个稳定的 <em>Borg命名服务</em> (BNS)，包括 cell 名，job 名和 task id</li><li>Borg将 <em>task</em> 的主机名和端口写入 Chubby，用于 RPC 系统查找 task endpoint</li><li>Borg还会将 <em>job</em> size与其运行状态写入Chubby，便于load balancer平衡流量</li></ul></li></ul></li><li><h2 id=borg的架构>Borg的架构 <a href=#borg%e7%9a%84%e6%9e%b6%e6%9e%84 class=anchor>🔗</a></h2><ul><li><em>Borgmaster</em><ul><li>主管理进程<ul><li>逻辑上的“单点”，有5个在线备份，使用Paxos选举master</li><li>状态存储在内存中，并且备份在高可靠性的Paxos存储中</li></ul></li><li>调度进程<ul><li>可行性检查<ul><li>用于找到满足任务约束、具备足够可用资源的一组机器</li></ul></li><li>打分（scoring）<ul><li>在“可行机器”中根据用户偏好，为机器打分</li><li>打分策略<ul><li>worst fit（E-PVN的变种）会将任务分散到不同的机器上<ul><li>有余量应对流量的尖峰</li><li>会导致资源的碎片化，阻碍大型<em>task</em>的部署</li></ul></li><li>best fit，会尽量“紧凑”的使用机器，以减少资源碎片<ul><li>便于大型<em>task</em>的部署</li><li>错误的资源估计会被“惩罚”，尤其影响突发的负载</li><li>影响利于富裕计算资源的batch jobs</li></ul></li><li>混合模型，尽量减少“受困资源”，即因为其它资源被完全占用而无法分配出去的资源</li></ul></li></ul></li><li>优化<ul><li>启动时间优化<ul><li>中位数启动时间为25s，80%用于安装相关依赖</li><li>将相关<em>task</em>优先分配到拥有相关依赖的机器上</li><li>使用 <em>tree-like</em> 或 <em>torrent-like</em> 机制，并发的分发相关依赖</li></ul></li><li>计算开销优化<ul><li>使得Borg能管理更多的机器</li><li>打分缓存：将可行性检查和打分结果缓存</li><li>等价类：同一 <em>job</em> 中的 <em>task</em> 通常具有类似的约束，因此可以将多个任务视为一个等价类</li><li>松弛随机化：计算所有机器的可行性和得分代价太高，可以随机取样一批机器，然后选择其中一个“足够好”的机器</li></ul></li></ul></li></ul></li></ul></li><li><em>Borglet</em><ul><li><em>Borglet</em> 是运行在每台机器上的本地代理，管理本地的任务和资源</li><li><em>Borgmaster</em> 会周期性地向每一个Borglet拉取当前状态，易于控制通信速度，避免“恢复风暴”</li><li>为了性能可扩展性，每个Borgmaster副本会运行无状态的 <em>link shard</em> 去处理与部分Borglet通信<ul><li>当 <em>Borgmaster</em> 重新选举时，<em>link shard</em> 会重新划分分区</li><li><em>link shard</em> 会聚合和压缩信息，仅仅向被Borgmaster报告状态的更新，以此减少更新负载</li></ul></li><li>如果 <em>Borglet</em> 多轮没有响应资源查询，则会被标记为down。运行其上的任务会被重新调度到其他机器。如果恢复通信，则 <em>Borgmaster</em> 会通知 <em>Borglet</em> 杀死已经重新调度的任务，以此保证任务的唯一性</li><li>Borglet与Borgmaster失去联系时，仍会继续处理相关任务。以应对 <em>Borgmaster</em> 的暂时失效</li></ul></li></ul></li><li><h2 id=可靠性>可靠性 <a href=#%e5%8f%af%e9%9d%a0%e6%80%a7 class=anchor>🔗</a></h2><ul><li>自动重新调度器被驱逐的任务</li><li>将任务分散到不同的失败域中</li><li>限制一个作业中同时失败任务的个数和中断率</li><li>使用声明式的期望状态表示和幂等的变更操作，以便无害地重新提交请求</li><li>对于机器级别的失效，限制其重新调度的速率，因为难以区分大规模机器故障和网络分区</li><li>避免重试引发错误的&lt;任务-机器>匹配对</li><li>关键数据持久化，写入磁盘</li></ul></li><li><h2 id=资源利用和效率>资源利用和效率 <a href=#%e8%b5%84%e6%ba%90%e5%88%a9%e7%94%a8%e5%92%8c%e6%95%88%e7%8e%87 class=anchor>🔗</a></h2><ul><li>评估方法<ul><li><em>cell compaction</em>：通过移除机器来找出给定工作负载能适应的最小的单元大小，然后反复从头开始重新打包工作负载，以确保不会因错误的配置而陷入困境</li></ul></li><li>“单元共享”：在同一台机器上运行生产任务和非生产任务，以优化资源使用<ul><li>实验表明，共享资源会影响实际的CPU计算性能</li><li>但是在节约成本的巨大优势上面，CPU性能的退化是可以容忍的</li></ul></li><li>“大型单元”：允许超大型计算任务，减少任务的碎片化</li><li>细粒度资源请求<ul><li>以千分之一的CPU核，和内存、磁盘的字节数为资源请求的最小单元</li><li>相比预设资源分配（套餐），可以避免额外的资源开销</li></ul></li><li>资源回收<ul><li>对于可以容忍低质量资源的工作（例如批处理作业），Borg会评估任务将使用的资源，并回收空闲资源</li><li>最初的预留值与其资源请求一致，然后300秒之后，会慢慢降低到实际使用率外加一个安全边缘</li><li>如果利用率超过资源预留值，预留值会快速增长。</li></ul></li></ul></li><li><h2 id=隔离与安全性>隔离与安全性： <a href=#%e9%9a%94%e7%a6%bb%e4%b8%8e%e5%ae%89%e5%85%a8%e6%80%a7 class=anchor>🔗</a></h2><ul><li>安全隔离<ul><li>使用Linux chroot jail在共享同一台机器的任务之间确保安全性</li></ul></li><li>性能隔离<ul><li>基于cgroup的资源容器，允许详细的资源核算并执行限制，防止任务相互干扰，确保稳定和可预测的性能</li><li>使用<em>appclass</em>，尽可能保证延迟敏感服务的资源使用</li><li>区分<em>可压缩资源</em> 和 <em>不可压缩资源</em><ul><li>可压缩资源（compressiable） - CPU%和Disk IO，可以暂时限流</li><li>不可压缩资源（non-compressible） - 内存、磁盘占用，需要清除优先级低的线程</li></ul></li><li>内核的CPU调度器，允许根据每个资源容器的负载状况来动态决定是否要驱逐低优先级任务，同时避免多个高优先级任务在一个cpu上争抢<ul><li>仍在尝试cpu调度时更好的考虑线程亲和、NUMA亲和等策略</li></ul></li></ul></li></ul></li><li><h2 id=经验教训>经验教训： <a href=#%e7%bb%8f%e9%aa%8c%e6%95%99%e8%ae%ad class=anchor>🔗</a></h2><ul><li><h3 id=负面经验>负面经验 <a href=#%e8%b4%9f%e9%9d%a2%e7%bb%8f%e9%aa%8c class=anchor>🔗</a></h3><ul><li><em>Job</em>作为<em>Task</em>的唯一分组机制的局限性<ul><li>缺乏将整个多<em>Job</em>服务作为单一实体进行管理，或引用服务相关<em>Job</em>（如Canary与Prod滚动更新）的方式</li><li>用户会在<em>Job</em>名称中编入拓扑，并构建外部管理工具来解析这些名称，这导致了滚动更新和作业调整大小等问题的不灵活语义</li><li>Kubernetes通过使用标签组织其调度单元（Pods），提供了更多灵活性</li></ul></li><li>单个IP地址带来的复杂性<ul><li>同一台机器上的所有任务共享该机器的单个IP地址和端口空间</li><li>导致端口也成为一种资源，在调度时候需要被考虑</li><li>Kubernetes采用了更友好的方法，每个Pod和服务都获取自己的IP地址，从而简化了这些复杂性。</li></ul></li><li>偏向于高级用户<ul><li>Borg提供了一整套面向“高级用户”的功能，允许他们细致调整程序运行方式</li><li>这种API的丰富性使得对于“普通”用户更加困难，并限制了其演变</li><li>Google构建了自动化工具，对于允许“失败”的应用程序，通过实验来探测适当配置</li></ul></li></ul></li><li><h3 id=积极经验>积极经验 <a href=#%e7%a7%af%e6%9e%81%e7%bb%8f%e9%aa%8c class=anchor>🔗</a></h3><ul><li>Allocs是有用的<ul><li>Kubernetes中的Alloc等效物是Pod，它是一个资源包，用于一个或多个容器，总是被调度到同一台机器上并可以共享资源</li></ul></li><li>集群管理不仅是任务管理<ul><li>尽管Borg的主要角色是管理任务和机器的生命周期，但运行在Borg上的应用程序从许多其他集群服务中受益，包括命名和负载均衡</li><li>Kubernetes使用服务抽象支持命名和负载均衡，服务有一个名称和一组由标签选择器定义的动态Pods。</li></ul></li><li>自省至关重要<ul><li>尽管Borg几乎总是“运行良好”，但当出现问题时，找到根本原因可能具有挑战性</li><li>Borg的重要设计决策之一是向所有用户展示调试信息</li><li>Kubernetes旨在复制Borg的许多内省技术，例如，它配备了cAdvisor等工具进行资源监控和基于Elasticsearch/Kibana和Fluentd的日志聚合</li></ul></li><li>主控节点是分布式系统的核心<ul><li>Borgmaster最初被设计为一个单体系统，但随着时间的推移，它变得更像是一个内核，位于协作管理用户作业的一系列服务的中心</li><li>Kubernetes架构更进一步，它有一个核心的API服务器，仅负责处理请求和操纵底层状态对象，集群管理逻辑被构建为小型可组合的微服务，这些服务是这个API服务器的客户端​​</li></ul></li></ul></li></ul></li><li><a href=https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/>论文</a></li></ul><div class="alert alert-info" role=alert>本文部分内容由ChatGPT4生成</div></div></section><section class=list-item><h1 class=title><a href=/posts/tl-dr-autopilot-automatic-data-center-management/>[TL;DR] 论文阅读：Autopilot - 自动化数据中心管理</a></h1><div class=tips><div class=date><time datetime="2023-12-22 23:32:00 +0000 UTC">2023/12/22</time></div><div class=tags><span>Tags:</span>
<a href=/tags/autopilot>Autopilot</a>
<a href=/tags/data-center>Data Center</a>
<a href=/tags/data-center-management>Data Center Management</a></div></div><div class=summary><ul><li><h2 id=tldr>TL;DR <a href=#tldr class=anchor>🔗</a></h2><ul><li>Autopilot是微软用来自动化运营大规模网络服务的基础架构</li><li>其设计核心是Device Manager，一个基于Paxos的强一致性分布式状态机，用来保存整个系统的“实际真相”（ground truth），并且根据整个系统的状态确定下一步的行动</li><li>其它子模块通过与Device Manager通信，在“最终一致性”模型下获取系统信息并执行命令，确保更新可能不是即时的，但最终会在系统中传播</li></ul></li><li><h2 id=概述>概述： <a href=#%e6%a6%82%e8%bf%b0 class=anchor>🔗</a></h2><ul><li>微软运营大规模网络服务，需要可靠的数据中心自动管理​​</li><li>为了降低数据中心的运营和资本支出而设计​​</li><li>负责自动化软件配置和部署、系统监控，以及执行修复操作来处理软件和硬件的故障</li><li>微观的策略则交由各个应用程序来确定。例如，确定哪些计算机应运行哪些软件，或者精确地定义和检测需要修复的故障</li></ul></li><li><h2 id=设计原则>设计原则： <a href=#%e8%ae%be%e8%ae%a1%e5%8e%9f%e5%88%99 class=anchor>🔗</a></h2><ul><li>基于大规模“商品级计算机系统”的经济性和不可靠性，Autopilot采用容错和简化设计​​</li><li>容错设计：非拜占庭式故障模型，解决数据中心的控制环境问题<ul><li>“非拜占庭式故障模型”假设系统中的错误不是恶意或欺诈性的。在这种模型中，系统的故障被认为是由于一些常规原因，如硬件故障、软件缺陷或网络问题</li></ul></li><li>简化设计：<ul><li>强调简单性和容错性</li><li>在构建大型的可靠、可维护系统时，常常选择简单设计而非更高效或看似更优雅但更复杂的解决案。</li></ul></li></ul></li><li><h2 id=系统概览>系统概览： <a href=#%e7%b3%bb%e7%bb%9f%e6%a6%82%e8%a7%88 class=anchor>🔗</a></h2><ul><li>Autopilot分为多个组件<ul><li><img src="https://github.com/Wizmann/assets/blob/master/wizmann-pic/image_1703238379499_0.png?raw=true" alt=image.png></li></ul></li><li>平衡弱一致性和强一致性之间的抉择<ul><li>弱一致性：增强可用性</li><li>强一致性：简化设计</li></ul></li><li>Device Manager - 状态和逻辑管理<ul><li>所有关于系统应处于的“实际真相”（ground truth）状态以及更新这一状态的逻辑，都保存在一个称为 Device Manager 的强一致性状态机中，通常分布在5至10台计算机上</li><li>使用 Paxos 算法实现副本间的一致性，同时通过批处理更新以平衡延迟和吞吐量</li></ul></li><li>Device Manager与“卫星服务”<ul><li>“卫星服务”在发现 Device Manager 状态需要时，惰性地向自身或其客户端的同步信息</li><li>如果“卫星服务”发现集群中的故障或不一致，它不会尝试纠正，而是将问题报告给 Device Manager<ul><li>Autopilot会综合这些信息做出下一步决定</li></ul></li><li>当 Device Manager 更新其状态时，会通知“卫星服务”。“卫星服务”也会通过心跳信息尝试拉取最新的状态。简化设计的同时，并且保证最终一致性/正确性。</li></ul></li></ul></li><li><h2 id=底层服务>底层服务： <a href=#%e5%ba%95%e5%b1%82%e6%9c%8d%e5%8a%a1 class=anchor>🔗</a></h2><ul><li>使用稳定的Windows Server操作系统镜像，包含Autopilot配置文件和服务​​</li><li>配置服务（Provisioning）包括DHCP和网络引导，不断扫描网络中新接入的计算机​​<ul><li>通过Device Manager提供的信息来决定需要运行的操作系统及二进制程序</li></ul></li><li>应用部署<ul><li>定义不同机器类型，存储不同配置文件和应用二进制文件​​</li><li>部署新代码时，以Scale unit为单位更新/回滚各机器类型的配置​​</li></ul></li></ul></li><li><h2 id=自动修复服务>自动修复服务 <a href=#%e8%87%aa%e5%8a%a8%e4%bf%ae%e5%a4%8d%e6%9c%8d%e5%8a%a1 class=anchor>🔗</a></h2><ul><li>使用最小化的故障检测和恢复模型，以节点或交换机为单位，不处理特定进程的错误<ul><li>只包括Reboot / ReImage / Replace 三种操作</li><li>Autopilot无需对错误归因，也不需要相关的错误处理逻辑</li></ul></li><li>用看门狗进行故障报告​​，检测特定的属性，并上报给Device Manager</li><li>Device Manager作为一个集中式程序，控制机器的自动修复，并且控制同时进行修复机器的数量</li><li><img src="https://github.com/Wizmann/assets/blob/master/wizmann-pic/image_1703254394216_0.png?raw=true" alt=image.png></li></ul></li><li><h2 id=监控服务>监控服务： <a href=#%e7%9b%91%e6%8e%a7%e6%9c%8d%e5%8a%a1 class=anchor>🔗</a></h2><ul><li>记录性能计数器和日志，收集服务形成分布式集合和聚合树​​</li></ul></li><li><h2 id=案例研究---indexserving>案例研究 - IndexServing： <a href=#%e6%a1%88%e4%be%8b%e7%a0%94%e7%a9%b6---indexserving class=anchor>🔗</a></h2><ul><li>介绍Windows Live Search如何与Autopilot交互，保持高可用性​​</li><li>对于需要高可用性和低延迟的面向客户服务的应用程序，需要在基础的 Autopilot 组件之上增加定制的容错层<ul><li>使用Load balancer和定制的监控服务来探测失效的或者慢速的节点，并且将结论上报到Autopilot</li></ul></li></ul></li><li><h2 id=经验与教训>经验与教训： <a href=#%e7%bb%8f%e9%aa%8c%e4%b8%8e%e6%95%99%e8%ae%ad class=anchor>🔗</a></h2><ul><li>对于关键的配置文件，进行checksum检查是必须的<ul><li>避免人工失误（例如部署因Debug而临时修改的配置）或者其它意外问题</li></ul></li><li>网络是不可靠的<ul><li>TCP/IP的checksum非常弱，所以需要应用层面的额外检查</li><li>网络硬件经常翻转数据流中的bit位，导致大量的重试或者未被网络层检测到的数据错误</li></ul></li><li>一些节点偶尔会运行的异常慢，但是并不会停止工作。这种问题与“失败停止错误”一样需要被及时检测到</li><li>节流与负荷削减对于自动化系统非常重要<ul><li>失效检测模块需要有效的区分节点失效与节点过载的区别</li><li>简单的移除节点可能会导致级联式的失效，进而使整个系统失效</li></ul></li></ul></li><li><a href=https://www.semanticscholar.org/paper/Autopilot%3A-automatic-data-center-management-Isard/a531d33efc600a8770316db71dc06a7599f9547a>论文</a></li></ul><div class="alert alert-info" role=alert>本文大（划掉）部分内容由ChatGPT4生成</div></div></section><section class=list-item><h1 class=title><a href=/posts/spin-promela-concurrent-queue-1/>使用 SPIN/Promela 对多线程 Concurrent FIFO Queue 进行建模与验证</a></h1><div class=tips><div class=date><time datetime="2023-12-17 00:00:00 +0000 UTC">2023/12/17</time></div><div class=tags><span>Tags:</span>
<a href=/tags/spin>SPIN</a>
<a href=/tags/promela>Promela</a>
<a href=/tags/spin/promela>SPIN/Promela</a>
<a href=/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B>多线程</a>
<a href=/tags/multi-thread>multi-thread</a></div></div><div class=summary><h2 id=引言>引言 <a href=#%e5%bc%95%e8%a8%80 class=anchor>🔗</a></h2><p>并发编程中设计和验证多线程数据结构是一项极大的挑战，即使是实现一个简单的数据结构（见<a href=/implement-non-blocking-queue.html>《实现一个无锁消息队列》</a>一文），都需要不少的脑力、讨论与实践才可以尽可能保证其正确性。</p><p>本文尝试使用 SPIN/Promela 对多线程环境下的 Concurrent FIFO Queue 的一种实现进行建模与验证。</p><h2 id=concurrent-fifo-queue-的设计>Concurrent FIFO Queue 的设计 <a href=#concurrent-fifo-queue-%e7%9a%84%e8%ae%be%e8%ae%a1 class=anchor>🔗</a></h2><p>为了保证多线程操作的正确性，我们采用了以下关键设计：</p><ul><li>Dummy Head 和 Dummy Tail 节点：引入这两个节点简化了队列操作逻辑，降低并发中的复杂性</li><li>Dummy Tail Data 指针作为“锁”：这个方法确保多个线程不会同时操作尾节点，降低了对锁的依赖</li><li>利用指针赋值的原子性：通过这种方式，减少了锁的使用，提高了效率</li></ul><h2 id=spinpromela-建模中的考虑因素>SPIN/Promela 建模中的考虑因素 <a href=#spinpromela-%e5%bb%ba%e6%a8%a1%e4%b8%ad%e7%9a%84%e8%80%83%e8%99%91%e5%9b%a0%e7%b4%a0 class=anchor>🔗</a></h2><p>在使用 SPIN/Promela 建模时，我们面临了几个挑战：</p></div></section><section class=list-item><h1 class=title><a href=/posts/simple-cas-model-in-spin-promela/>在SPIN/Promela中模拟CAS（Compare-and-Swap）</a></h1><div class=tips><div class=date><time datetime="2023-12-15 00:00:00 +0000 UTC">2023/12/15</time></div><div class=tags><span>Tags:</span>
<a href=/tags/spin>SPIN</a>
<a href=/tags/promela>Promela</a>
<a href=/tags/spin/promela>SPIN/Promela</a>
<a href=/tags/cas>CAS</a>
<a href=/tags/compare-ans-swap>Compare-ans-Swap</a></div></div><div class=summary><p>CAS（Compare-And-Swap）是一种在多线程编程中常用的数据同步方法，它通过比较和交换操作来保证数据的一致性。然而，在SPIN/Promela中没有直接的CAS对应实现。</p></div></section><section class=list-item><h1 class=title><a href=/posts/tl-dr-rarest-first-and-choke-algorithms-are-enough/>[tl;dr] 论文阅读：Rarest First and Choke Algorithms Are Enough</a></h1><div class=tips><div class=date><time datetime="2023-12-08 00:00:00 +0000 UTC">2023/12/08</time></div><div class=tags><span>Tags:</span>
<a href=/tags/bittorrent>BitTorrent</a>
<a href=/tags/distributed-system>Distributed System</a></div></div><div class=summary><ul><li><h2 id=基本概念>基本概念 <a href=#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5 class=anchor>🔗</a></h2><ul><li><strong>Peer</strong>：BitTorrent P2P下载的参与者</li><li><strong>Leecher</strong>：“吸血者”，仍在下载过程中的peer</li><li><strong>Seeder</strong>：做种者，下载完成后还在继续做种的peer</li><li><strong>Piece</strong>：Piece是文件的数据单元。当文件被分享时，它被分割成多个大小相等的片段，称为"pieces"。这些pieces是peer间传输的基本单位</li></ul></li><li><h2 id=最稀有优先算法rarest-first-algorithm>&ldquo;最稀有优先算法&rdquo;（Rarest First Algorithm） <a href=#%e6%9c%80%e7%a8%80%e6%9c%89%e4%bc%98%e5%85%88%e7%ae%97%e6%b3%95rarest-first-algorithm class=anchor>🔗</a></h2><ul><li>&ldquo;最稀有优先算法&rdquo;（Rarest First Algorithm）是BitTorrent协议中的一个关键策略，用于决定哪些数据块（piece）首先被下载和分享。这个算法的核心目标是优化整个网络中数据的分布，确保更快的下载速度和更高的效率。</li><li><h3 id=基本原理>基本原理 <a href=#%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86 class=anchor>🔗</a></h3><ul><li><strong>数据块的稀有度</strong><ul><li>在BitTorrent网络中，文件被分割成许多小的数据块。<ul><li>“最稀有优先”算法的目的是优先下载那些网络中数量最少的数据块。</li></ul></li></ul></li><li><strong>选择下载的块</strong>：<ul><li>当一个peer加入Torrent网络，并开始下载文件时，它首先会从所有连接的peer那里获取有关哪些数据块是稀有的信息。<ul><li>然后，它优先请求下载那些最稀有的数据块。</li></ul></li></ul></li><li><strong>动态调整</strong>：<ul><li>随着下载的进行，每个peer会不断更新和重新评估网络中每个数据块的稀有度，并相应地调整其下载优先级。</li></ul></li><li><h3 id=算法的重要性>算法的重要性 <a href=#%e7%ae%97%e6%b3%95%e7%9a%84%e9%87%8d%e8%a6%81%e6%80%a7 class=anchor>🔗</a></h3><ul><li><strong>提高效率</strong>：通过优先下载最稀有的块，这个算法帮助加快了文件的整体下载速度。一旦最稀有的块被更多peer获取，它们就更容易被进一步分享和分发。</li><li><strong>防止瓶颈</strong>：如果没有这个算法，某些数据块可能会变得很难获得，导致下载过程在接近完成时放慢，这被称为“最后一块问题”（Last Piece Problem）。</li><li><strong>促进平等分享</strong>：这种方法鼓励peer分享它们拥有的稀有块，从而提高了整个网络中的合作和资源共享。</li></ul></li></ul></li><li><h3 id=实际应用>实际应用 <a href=#%e5%ae%9e%e9%99%85%e5%ba%94%e7%94%a8 class=anchor>🔗</a></h3><ul><li>在BitTorrent网络中，这个算法对于确保高效的数据分发至关重要。它不仅提高了单个用户的下载速度，而且还提高了整个网络的效率，确保了资源在用户之间的均衡分配。通过这种方式，BitTorrent网络能够有效地避免瓶颈和提高数据的可用性，即使在面对大量用户的情况下也是如此。</li></ul></li><li><h3 id=结论>结论 <a href=#%e7%bb%93%e8%ae%ba class=anchor>🔗</a></h3><ul><li>最稀有优先算法是BitTorrent网络高效运行的关键组成部分。它通过智能地选择下载和分享网络中最稀有的数据块，提高了资源的整体分布和可用性，确保了快速、平衡的文件共享。</li></ul></li></ul></li><li><h2 id=窒息算法choking-algorithm>&ldquo;窒息算法&rdquo;（Choking Algorithm） <a href=#%e7%aa%92%e6%81%af%e7%ae%97%e6%b3%95choking-algorithm class=anchor>🔗</a></h2><ul><li>&ldquo;窒息算法&rdquo;（Choking Algorithm）是BitTorrent协议中的一个关键组成部分，用于管理多个peer之间的数据传输。这个算法帮助优化带宽的使用，确保网络中的资源被高效合理地分配。其核心目的是促进peer间的合作和数据的快速分发。</li><li><h3 id=窒息算法的基本原理>窒息算法的基本原理 <a href=#%e7%aa%92%e6%81%af%e7%ae%97%e6%b3%95%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86 class=anchor>🔗</a></h3><ul><li><strong>选择和窒息（Choking and Unchoking）</strong><ul><li>在BitTorrent网络中，每个peer同时维护着一组“窒息”（choked）和“未窒息”（unchoked）的peer名单。<ul><li>被“窒息”的peer无法从窒息方接收文件数据，而“未窒息”的peer可以进行数据交换。</li><li>这种状态是动态的，peer根据算法定期更新它们的窒息/未窒息peer名单。</li></ul></li></ul></li><li><strong>利益驱动的决策</strong><ul><li>算法核心是“利益驱动”（tit-for-tat）策略，即peer更倾向于向那些能给它提供数据的peer提供数据。<ul><li>这种方法鼓励peer分享数据，因为分享越多，获得数据的机会也越大。</li></ul></li></ul></li><li><strong>优化器</strong>：<ul><li>除了基于交换数据的量来决定窒息状态外，大多数BitTorrent客户端还实现了一个“优化器”（Optimizer），用于探索新的peer。<ul><li>通常，这是通过定期“未窒息”一个随机选择的peer来实现的，即使它在过去的数据交换中表现不佳或没有数据交换。</li></ul></li></ul></li><li><strong>窒息周期</strong>：<ul><li>peer定期评估其连接，并根据从其他peer接收到的数据速率来更新其窒息/未窒息名单</li></ul></li></ul></li><li><h3 id=窒息算法的重要性>窒息算法的重要性 <a href=#%e7%aa%92%e6%81%af%e7%ae%97%e6%b3%95%e7%9a%84%e9%87%8d%e8%a6%81%e6%80%a7 class=anchor>🔗</a></h3><ul><li><strong>合作促进</strong>：通过奖励那些分享资源的peer，窒息算法鼓励合作，提高了网络中的资源共享效率。</li><li><strong>防止自私行为</strong>：算法减少了自私peer（只下载不上传的）的优势，因为这些peer不太可能被其他peer“未窒息”。</li><li><strong>网络拥塞控制</strong>：它帮助控制网络拥塞，通过限制peer的连接数量和数据传输，优化带宽使用。</li></ul></li><li><h3 id=结论-1>结论 <a href=#%e7%bb%93%e8%ae%ba-1 class=anchor>🔗</a></h3><ul><li>窒息算法是BitTorrent协议高效性的关键，它通过一种简单但有效的方式来鼓励数据共享和合作，保证了整个网络的健康和高效运行。通过这种动态的窒息/未窒息机制，BitTorrent网络能够有效地管理带宽和连接，确保资源在网络中的快速且公平的分配。</li></ul></li></ul></li><li><h2 id=为什么说已经足够了>为什么说“已经足够了” <a href=#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%af%b4%e5%b7%b2%e7%bb%8f%e8%b6%b3%e5%a4%9f%e4%ba%86 class=anchor>🔗</a></h2><ul><li><blockquote><p>因为这是一门实验科学</p></div></section><section class=list-item><h1 class=title><a href=/posts/a2b/>A2B Game Solutions</a></h1><div class=tips><div class=date><time datetime="2021-11-18 00:00:00 +0000 UTC">2021/11/18</time></div><div class=tags><span>Tags:</span>
<a href=/tags/game>game</a>
<a href=/tags/a2b>a2b</a>
<a href=/tags/solution>solution</a></div></div><div class=summary><p>A2B is a &ldquo;zach-like&rdquo; programming game, which let you to use a very simple &ldquo;programming language&rdquo; to solve different problems for strings.</p><p>Personally, I highly recommand this game along with &ldquo;Shenzhen IO&rdquo; and &ldquo;Factorio&rdquo; as an beginner tutorial for anyone who wants to be a software engineer.</p><iframe src=https://store.steampowered.com/widget/1720850/ frameborder=0 width=646 height=190></iframe>
<iframe src=https://store.steampowered.com/widget/504210/ frameborder=0 width=646 height=190></iframe>
<iframe src=https://store.steampowered.com/widget/427520/ frameborder=0 width=646 height=190></iframe><h2 id=spoiler-alert>Spoiler Alert <a href=#spoiler-alert class=anchor>🔗</a></h2><p>** The following article includes huge spoilers for A=B Game. **</p><p>If you have a different solution or a better solution. Feel free to share it with a comment.</p></div></section><section class=list-item><h1 class=title><a href=/posts/bbr-intro/>浅淡TCP BBR</a></h1><div class=tips><div class=date><time datetime="2021-08-17 00:00:00 +0000 UTC">2021/08/17</time></div><div class=tags><span>Tags:</span>
<a href=/tags/tcp>tcp</a>
<a href=/tags/networking>networking</a>
<a href=/tags/bbr>bbr</a></div></div><div class=summary><h2 id=背景>背景 <a href=#%e8%83%8c%e6%99%af class=anchor>🔗</a></h2><p>在一对跨地域的机器（美国&lt;->香港），使用TCP（Cubic拥塞控制算法）通信throughput最高2MB/s，丢包率0.02%。使用UDP通信throughput最高能达到140MB/s。</p><p>这是一个非常典型的长肥管道（LFN），并且丢包率比较高。尝试使用BBR算法后，throughput可达50MB/s+（Windows系统，通信协议使用用户态MsQuic）。</p></div></section><section class=list-item><h1 class=title><a href=/posts/paper-wisckey/>论文阅读-WiscKey：SSD友好的KV分离存储引擎</a></h1><div class=tips><div class=date><time datetime="2021-08-15 00:00:00 +0000 UTC">2021/08/15</time></div><div class=tags><span>Tags:</span>
<a href=/tags/wisckey>wisckey</a>
<a href=/tags/rocksdb>rocksdb</a>
<a href=/tags/leveldb>leveldb</a>
<a href=/tags/lsm-tree>lsm-tree</a>
<a href=/tags/storage>storage</a></div></div><div class=summary><h2 id=背景>背景 <a href=#%e8%83%8c%e6%99%af class=anchor>🔗</a></h2><h3 id=基于lsm-tree的存储引擎>基于LSM-Tree的存储引擎 <a href=#%e5%9f%ba%e4%ba%8elsm-tree%e7%9a%84%e5%ad%98%e5%82%a8%e5%bc%95%e6%93%8e class=anchor>🔗</a></h3><p>Log-Structed Merge-Tree (a.k.a. LSM-Tree)是当下常用的一种基于磁盘的存储引擎。与Hash索引和B-Tree同为数据库核心的数据结构。</p><p>LSM-Tree的优势在于：</p><ol><li>无需将所有的Key索引在内存中。可以通过分级查找的方式，查询到特定KV在磁盘中的偏移量</li><li>数据写入与合并使用顺序追加写，最大程度的利用磁盘的顺序写性能</li><li>对于数据写入，会使用batch方式写入磁盘</li><li>支持范围查询</li></ol><p>LSM-Tree的劣势在于：</p></div></section></div><nav class=pagination><a class="enabled current" href=/>1</a>
<a class=enabled href=/page/2/>2</a>
<a class=enabled href=/page/3/>3</a>
<span>··</span>
<a class=enabled href=/page/6/>6</a></nav></div></div><div class=side><div class=side-recent><h2 class=side-title><a href=/posts/>Recent Posts</a></h2><hr><ul><li><a href=/posts/why-not-start-with-ddia-part-1/>为什么我不建议你阅读《数据密集型应用系统设计》（之一）</a></li><li><a href=/posts/vertical-axis-wind-turbine-3d-model/>风力涡轮机 3D 模型 / Vertical Axis Wind Turbine (VAWT) 3D Model</a></li><li><a href=/posts/press-pad-3d-model/>3D打印解压玩具 / 3D Printed Fidget Toy</a></li><li><a href=/posts/lava-store/>论文阅读：LavaStore - 高性能、本地存储引擎的演进</a></li><li><a href=/posts/std-smart-ptrs-cpp-for-the-antiquated-4/>动手实现智能指针 （上篇） - C++ for the Antiquated（之四）</a></li></ul></div><div class=side-categories><h2>Categories</h2><hr><ul></ul></div><div class=side-tags><h2>Tags</h2><hr><ul><li><a href=/tags/.net>.net (1)</a></li><li><a href=/tags/3d-printing>3d printing (2)</a></li><li><a href=/tags/a2b>a2b (1)</a></li><li><a href=/tags/ahk>ahk (1)</a></li><li><a href=/tags/algorithm>algorithm (26)</a></li><li><a href=/tags/alloca>alloca (1)</a></li><li><a href=/tags/allocate>allocate (1)</a></li><li><a href=/tags/arduino>arduino (1)</a></li><li><a href=/tags/asm>asm (1)</a></li><li><a href=/tags/async>async (2)</a></li><li><a href=/tags/atcoder>atcoder (1)</a></li><li><a href=/tags/autohotkey>autohotkey (1)</a></li><li><a href=/tags/autopilot>autopilot (1)</a></li><li><a href=/tags/azure>azure (2)</a></li><li><a href=/tags/b-tree>b-tree (1)</a></li><li><a href=/tags/basic-paxos>basic paxos (2)</a></li><li><a href=/tags/bbr>bbr (1)</a></li><li><a href=/tags/binary-indexed-tree>binary indexed tree (1)</a></li><li><a href=/tags/binary-tree>binary tree (1)</a></li><li><a href=/tags/bittorrent>bittorrent (1)</a></li><li><a href=/tags/borg>borg (1)</a></li><li><a href=/tags/bw-tree>bw-tree (1)</a></li><li><a href=/tags/c>c# (1)</a></li><li><a href=/tags/c++>c++ (6)</a></li><li><a href=/tags/cache>cache (1)</a></li><li><a href=/tags/cachegrind>cachegrind (1)</a></li><li><a href=/tags/cap>cap (1)</a></li><li><a href=/tags/career>career (1)</a></li><li><a href=/tags/cas>cas (3)</a></li><li><a href=/tags/ceph>ceph (1)</a></li><li><a href=/tags/chrome-extension>chrome-extension (2)</a></li><li><a href=/tags/cmpxchg>cmpxchg (2)</a></li><li><a href=/tags/cocurrency>cocurrency (1)</a></li><li><a href=/tags/code-golf>code golf (1)</a></li><li><a href=/tags/codeforces>codeforces (14)</a></li><li><a href=/tags/compare-ans-swap>compare-ans-swap (1)</a></li><li><a href=/tags/computational-geometry>computational geometry (1)</a></li><li><a href=/tags/consistency>consistency (1)</a></li><li><a href=/tags/cpp>cpp (9)</a></li><li><a href=/tags/cpu>cpu (1)</a></li><li><a href=/tags/cse351>cse351 (2)</a></li><li><a href=/tags/csharp>csharp (1)</a></li><li><a href=/tags/css>css (1)</a></li><li><a href=/tags/data-center>data center (1)</a></li><li><a href=/tags/data-center-management>data center management (1)</a></li><li><a href=/tags/defer>defer (1)</a></li><li><a href=/tags/distributed-system>distributed system (4)</a></li><li><a href=/tags/epoll>epoll (1)</a></li><li><a href=/tags/ergodone>ergodone (1)</a></li><li><a href=/tags/fifo>fifo (1)</a></li><li><a href=/tags/flatbuffer>flatbuffer (2)</a></li><li><a href=/tags/fn-layer>fn-layer (1)</a></li><li><a href=/tags/front-end-development>front-end development (1)</a></li><li><a href=/tags/functional-programming>functional programming (1)</a></li><li><a href=/tags/game>game (1)</a></li><li><a href=/tags/gcj>gcj (1)</a></li><li><a href=/tags/geohash>geohash (1)</a></li><li><a href=/tags/geometric>geometric (1)</a></li><li><a href=/tags/geometry>geometry (1)</a></li><li><a href=/tags/get-things-done>get things done (1)</a></li><li><a href=/tags/google>google (3)</a></li><li><a href=/tags/graph>graph (1)</a></li><li><a href=/tags/head-first>head-first (1)</a></li><li><a href=/tags/heap>heap (1)</a></li><li><a href=/tags/herd7>herd7 (1)</a></li><li><a href=/tags/induction>induction (2)</a></li><li><a href=/tags/interview>interview (5)</a></li><li><a href=/tags/keyboard>keyboard (2)</a></li><li><a href=/tags/kubernetes>kubernetes (1)</a></li><li><a href=/tags/lavastore>lavastore (1)</a></li><li><a href=/tags/leetcode>leetcode (4)</a></li><li><a href=/tags/leveldb>leveldb (1)</a></li><li><a href=/tags/linkedin>linkedin (1)</a></li><li><a href=/tags/linux>linux (1)</a></li><li><a href=/tags/litmus>litmus (1)</a></li><li><a href=/tags/lock-less>lock-less (1)</a></li><li><a href=/tags/lsm-tree>lsm-tree (1)</a></li><li><a href=/tags/markdown>markdown (1)</a></li><li><a href=/tags/median>median (1)</a></li><li><a href=/tags/memory>memory (1)</a></li><li><a href=/tags/memory-barrier>memory-barrier (3)</a></li><li><a href=/tags/mesi>mesi (1)</a></li><li><a href=/tags/message-queue>message queue (1)</a></li><li><a href=/tags/metadata>metadata (1)</a></li><li><a href=/tags/metaprogramming>metaprogramming (1)</a></li><li><a href=/tags/microsoft>microsoft (2)</a></li><li><a href=/tags/misaka>misaka (1)</a></li><li><a href=/tags/modern-c++>modern c++ (1)</a></li><li><a href=/tags/modern-cpp>modern cpp (4)</a></li><li><a href=/tags/mosca>mosca (1)</a></li><li><a href=/tags/mq>mq (1)</a></li><li><a href=/tags/multi-paxos>multi paxos (1)</a></li><li><a href=/tags/multi-thread>multi-thread (3)</a></li><li><a href=/tags/multiprocess>multiprocess (1)</a></li><li><a href=/tags/multithread>multithread (3)</a></li><li><a href=/tags/network>network (1)</a></li><li><a href=/tags/networking>networking (4)</a></li><li><a href=/tags/non-blocking>non-blocking (1)</a></li><li><a href=/tags/normal-distribution>normal-distribution (1)</a></li><li><a href=/tags/ocaml>ocaml (1)</a></li><li><a href=/tags/ot>ot (1)</a></li><li><a href=/tags/parallel>parallel (1)</a></li><li><a href=/tags/partition>partition (1)</a></li><li><a href=/tags/paxos>paxos (2)</a></li><li><a href=/tags/pecifica>pecifica (1)</a></li><li><a href=/tags/pelican>pelican (1)</a></li><li><a href=/tags/phxrpc>phxrpc (8)</a></li><li><a href=/tags/pl>pl (1)</a></li><li><a href=/tags/poi>poi (1)</a></li><li><a href=/tags/poll>poll (1)</a></li><li><a href=/tags/powershell>powershell (1)</a></li><li><a href=/tags/priority-queue>priority queue (1)</a></li><li><a href=/tags/priority_queue>priority_queue (1)</a></li><li><a href=/tags/profile>profile (1)</a></li><li><a href=/tags/programming-interview>programming interview (1)</a></li><li><a href=/tags/promela>promela (2)</a></li><li><a href=/tags/protobuf>protobuf (1)</a></li><li><a href=/tags/protocol>protocol (4)</a></li><li><a href=/tags/python>python (3)</a></li><li><a href=/tags/quartile>quartile (1)</a></li><li><a href=/tags/queue>queue (2)</a></li><li><a href=/tags/quick-sort>quick sort (1)</a></li><li><a href=/tags/quora>quora (1)</a></li><li><a href=/tags/racket>racket (1)</a></li><li><a href=/tags/raft>raft (2)</a></li><li><a href=/tags/rocksdb>rocksdb (2)</a></li><li><a href=/tags/rpc>rpc (4)</a></li><li><a href=/tags/social-network>social network (1)</a></li><li><a href=/tags/socket>socket (1)</a></li><li><a href=/tags/solution>solution (2)</a></li><li><a href=/tags/sort>sort (1)</a></li><li><a href=/tags/spin>spin (4)</a></li><li><a href=/tags/spin/promela>spin/promela (2)</a></li><li><a href=/tags/stack>stack (2)</a></li><li><a href=/tags/stdfunction>std::function (1)</a></li><li><a href=/tags/stl>stl (1)</a></li><li><a href=/tags/storage>storage (3)</a></li><li><a href=/tags/storage-system>storage system (2)</a></li><li><a href=/tags/streambuf>streambuf (1)</a></li><li><a href=/tags/string>string (1)</a></li><li><a href=/tags/stup>stup (3)</a></li><li><a href=/tags/stylish>stylish (1)</a></li><li><a href=/tags/system>system (1)</a></li><li><a href=/tags/system-design>system design (5)</a></li><li><a href=/tags/tcp>tcp (4)</a></li><li><a href=/tags/tcpip>tcpip (1)</a></li><li><a href=/tags/thread>thread (3)</a></li><li><a href=/tags/tlv>tlv (1)</a></li><li><a href=/tags/twisted>twisted (1)</a></li><li><a href=/tags/ucontext>ucontext (2)</a></li><li><a href=/tags/udp>udp (3)</a></li><li><a href=/tags/useless>useless (1)</a></li><li><a href=/tags/userscript>userscript (1)</a></li><li><a href=/tags/valgrind>valgrind (1)</a></li><li><a href=/tags/wait-free>wait-free (1)</a></li><li><a href=/tags/was>was (1)</a></li><li><a href=/tags/wisckey>wisckey (1)</a></li><li><a href=/tags/workflowy>workflowy (1)</a></li><li><a href=/tags/wsl>wsl (1)</a></li><li><a href=/tags/yunfile>yunfile (1)</a></li><li><a href=/tags/zeromq>zeromq (1)</a></li><li><a href=/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B>并发编程 (1)</a></li><li><a href=/tags/%E7%B3%99%E5%BF%AB%E7%8C%9B>糙快猛 (1)</a></li><li><a href=/tags/%E5%88%9B%E9%80%A0%E5%8A%9B>创造力 (1)</a></li><li><a href=/tags/%E8%AF%BB%E4%B9%A6>读书 (2)</a></li><li><a href=/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B>多线程 (2)</a></li><li><a href=/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F>分布式系统 (6)</a></li><li><a href=/tags/%E5%88%86%E7%B1%BB%E5%99%A8>分类器 (1)</a></li><li><a href=/tags/%E5%85%AC%E5%BC%80%E8%AF%BE>公开课 (4)</a></li><li><a href=/tags/%E8%AE%A1%E6%95%B0>计数 (1)</a></li><li><a href=/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6>计算机科学 (1)</a></li><li><a href=/tags/%E9%93%BE%E8%A1%A8>链表 (1)</a></li><li><a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB>论文阅读 (1)</a></li><li><a href=/tags/%E9%9D%A2%E8%AF%95>面试 (1)</a></li><li><a href=/tags/%E5%AE%B9%E6%96%A5%E5%8E%9F%E7%90%86>容斥原理 (1)</a></li><li><a href=/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F>设计模式 (2)</a></li><li><a href=/tags/%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81>数据编码 (1)</a></li><li><a href=/tags/%E6%95%B0%E6%8D%AE%E5%BA%93>数据库 (4)</a></li><li><a href=/tags/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F>数据密集型应用系统 (1)</a></li><li><a href=/tags/%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B>数据模型 (1)</a></li><li><a href=/tags/%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F>数据系统 (1)</a></li><li><a href=/tags/%E6%80%9D%E7%BB%B4>思维 (1)</a></li><li><a href=/tags/%E7%AE%97%E6%B3%95>算法 (14)</a></li><li><a href=/tags/%E7%B4%A2%E5%BC%95>索引 (1)</a></li><li><a href=/tags/%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84>索引结构 (1)</a></li><li><a href=/tags/%E9%A2%98%E8%A7%A3>题解 (11)</a></li><li><a href=/tags/%E9%97%B2%E8%81%8A>闲聊 (3)</a></li><li><a href=/tags/%E5%8D%8F%E7%A8%8B>协程 (1)</a></li><li><a href=/tags/%E5%8E%8B%E7%BC%A9>压缩 (1)</a></li><li><a href=/tags/%E4%B8%80%E8%87%B4%E6%80%A7>一致性 (3)</a></li><li><a href=/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6>主从复制 (1)</a></li><li><a href=/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2>字符串 (1)</a></li><li><a href=/tags/%E6%9C%80%E5%B0%8F%E8%A1%A8%E7%A4%BA%E6%B3%95>最小表示法 (1)</a></li></ul></div></div></main><footer class=footer><div class=footer-row><a class=footer-item href=https://wizmann.top/posts/index.xml>Feed of Posts
<i class=icofont-rss></i></a></div></footer></body></html>
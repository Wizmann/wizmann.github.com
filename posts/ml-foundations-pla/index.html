<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=Content-Security-Policy content="script-src 'self'; style-src 'self' 'unsafe-inline'; object-src 'none'; base-uri 'none'"><link rel=stylesheet href=/css/style.feedcd92d05c2cf19ee7487656b358ee4805f831b7b39711851199d0a6f8934cf9ba379d02425d485c5b65ae299bdffda3770739545d595074076bf3ead284ab.css media=screen integrity="sha512-/u3NktBcLPGe50h2VrNY7kgF+DG3s5cRhRGZ0Kb4k0z5ujedAkJdSFxbZa4pm9/9o3cHOVRdWVB0B2vz6tKEqw==" crossorigin=anonymous><title>機器學習基石 - PLA算法初步</title>
<meta name=description content="什么是PLA算法 PLA = Perceptrons Learning Alogrithm
WikiPedia上有一个大概的历史背景介绍。
感知机（英语：Perceptron）是Frank Rosenblatt在1957年就职于Cornell航空实验室(Cornell Aeronautical Laboratory)时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈式人工神经网络，是一种二元线性分类器。
"><link rel=canonical href=https://wizmann.top/posts/ml-foundations-pla/><link rel=alternate hreflang=zh-CN href=https://wizmann.top/posts/ml-foundations-pla/><link rel=alternate hreflang=x-default href=https://wizmann.top/posts/ml-foundations-pla/><meta property="og:title" content="機器學習基石 - PLA算法初步"><meta property="og:description" content="什么是PLA算法
PLA = Perceptrons Learning Alogrithm
WikiPedia上有一个大概的历史背景介绍。

感知机（英语：Perceptron）是Frank Rosenblatt在1957年就职于Cornell航空实验室(Cornell Aeronautical Laboratory)时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈式人工神经网络，是一种二元线性分类器。"><meta property="og:type" content="article"><meta property="og:url" content="https://wizmann.top/posts/ml-foundations-pla/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2013-11-29T00:00:00+00:00"><meta property="article:modified_time" content="2013-11-29T00:00:00+00:00"><meta property="og:site_name" content="Maerlyn's Rainbow"><meta name=twitter:card content="summary"><meta name=twitter:title content="機器學習基石 - PLA算法初步"><meta name=twitter:description content="什么是PLA算法
PLA = Perceptrons Learning Alogrithm
WikiPedia上有一个大概的历史背景介绍。

感知机（英语：Perceptron）是Frank Rosenblatt在1957年就职于Cornell航空实验室(Cornell Aeronautical Laboratory)时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈式人工神经网络，是一种二元线性分类器。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"機器學習基石 - PLA算法初步","datePublished":"2013-11-29T00:00:00+00:00","dateModified":"2013-11-29T00:00:00+00:00","mainEntityOfPage":"https://wizmann.top/","publisher":{"@type":"Organization","name":"Maerlyn's Rainbow"},"wordcount":1098,"description":"什么是PLA算法 PLA = Perceptrons Learning Alogrithm\nWikiPedia上有一个大概的历史背景介绍。\n感知机（英语：Perceptron）是Frank Rosenblatt在1957年就职于Cornell航空实验室(Cornell Aeronautical Laboratory)时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈式人工神经网络，是一种二元线性分类器。\n","keywords":null}</script></head><body class="posts single d-flex flex-column min-vh-100"><header class=main-header><nav class="navbar navbar-expand-lg"><div class=container><a class=navbar-brand href=/>Maerlyn's Rainbow
</a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="menu-main navbar-nav me-auto mb-2 mb-lg-0"></ul></div></div></nav></header><div id=content><div class="container py-3"><h2 id=什么是pla算法>什么是PLA算法</h2><p>PLA = Perceptrons Learning Alogrithm</p><p>WikiPedia上有一个大概的历史背景介绍。</p><blockquote><p>感知机（英语：Perceptron）是Frank Rosenblatt在1957年就职于Cornell航空实验室(Cornell Aeronautical Laboratory)时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈式人工神经网络，是一种二元线性分类器。</p></blockquote><h2 id=pla算法的原理>PLA算法的原理</h2><p><img src=https://github.com/Wizmann/assets/raw/master/wizmann-tk-pic/blog-perceptron-Ncell.png alt=感知机示意图></p><blockquote><p>对于每种输入值(1 - D)，我们计算一个权重。当前神经元的总激发值(a)就等于每种输入值(x)乘以权重(w)之和。</p></blockquote><p>由此我们就可以推导出公式如下。</p><p><img src=https://github.com/Wizmann/assets/raw/master/wizmann-tk-pic/blog-perceptron-formula-1.jpg alt="neuron sum"></p><p>我们可以为这个“神经元”的激发值设定一个阈值<code>threshold</code>。</p><p>如果 <code>a > threshold</code>，则判定输入为正例。
如果 <code>a &lt; threshold</code>，则判定输入为负例。
对于 <code>a == threshold</code>的情况，认为是特殊情况，不予考虑。</p><p>所以，我们的感知器分类器就可以得到以下式子。</p><p><img src=https://github.com/Wizmann/assets/raw/master/wizmann-tk-pic/blog-perceptron-formula-2.png alt=perceptron-formula-2></p><p>我们在数据向量中加入了阈值，并把式子统一成向量积的形式。</p><h2 id=pla算法的错误修正>PLA算法的错误修正</h2><p>PLA算法是_错误驱动_的算法。</p><blockquote><p>当我们训练这个算法时，只要输出值是正确的，这个算法就不会进行任何数据的调整。反之，当输出值与实际值异号，这个算法就会自动调整参数的比重。</p></blockquote><p><img src=https://github.com/Wizmann/assets/raw/master/wizmann-tk-pic/blog-perceptron-update.png alt=错误修正></p><p>我们先取一个随机向量<code>W</code>，与现有的数据<code>X[i]</code>做点乘，取得结果的符号。</p><p>如果符号符合我们的预期的话，则<code>continue</code>。
否则就要对<code>W</code>进行修正。</p><p>修正的方式是<code>W += y * X[i]</code>，每一次修正都是减少现有向量<code>W</code>与向量<code>y * X[i]</code>的夹角，从而调整答案的正确性。</p><h2 id=naive-pla-与-pocket-pla>Naive PLA 与 Pocket PLA</h2><h3 id=naive-pla>Naive PLA</h3><p>Naive PLA算法的思想很简单。一直修正向量<code>W</code>，直到向量<code>W</code>满足所有数据为止。</p><p>代码如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> numpy <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>naive_pla</span>(datas):
</span></span><span style=display:flex><span>    w <span style=color:#f92672>=</span> datas[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    iteration <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>        iteration <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        false_data <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> data <span style=color:#f92672>in</span> datas:
</span></span><span style=display:flex><span>            t <span style=color:#f92672>=</span> dot(w, data[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> sign(data[<span style=color:#ae81ff>1</span>]) <span style=color:#f92672>!=</span> sign(t):
</span></span><span style=display:flex><span>                error <span style=color:#f92672>=</span> data[<span style=color:#ae81ff>1</span>]  
</span></span><span style=display:flex><span>                false_data <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>                w <span style=color:#f92672>+=</span> error <span style=color:#f92672>*</span> data[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>        print <span style=color:#e6db74>&#39;iter</span><span style=color:#e6db74>%d</span><span style=color:#e6db74> (</span><span style=color:#e6db74>%d</span><span style=color:#e6db74> / </span><span style=color:#e6db74>%d</span><span style=color:#e6db74>)&#39;</span> <span style=color:#f92672>%</span> (iteration, false_data, len(datas))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> false_data:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> w
</span></span></code></pre></div><h3 id=pocket-pla>Pocket PLA</h3><p>Naive PLA的一大问题就是如果数据有杂音，不能完美的分类的话，算法就不会中止。</p><p>所以，对于有杂音的数据，我们只能期望找到错误最少的结果。然后这是一个<code>NP Hard</code>问题。</p><p>Pocket PLA一个贪心的近似算法。和Naive PLA算法类似。</p><p>变顺序迭代为随机迭代，如果找出错误，则修正结果。在修正过程中，记录犯错误最少的向量。</p><p>代码如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>pocket_pla</span>(datas, limit):
</span></span><span style=display:flex><span>    <span style=color:#75715e>###############</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_calc_false</span>(vec):
</span></span><span style=display:flex><span>        res <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> data <span style=color:#f92672>in</span> datas:
</span></span><span style=display:flex><span>            t <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(vec, data[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> np<span style=color:#f92672>.</span>sign(data[<span style=color:#ae81ff>1</span>]) <span style=color:#f92672>!=</span> np<span style=color:#f92672>.</span>sign(t):
</span></span><span style=display:flex><span>                res <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> res
</span></span><span style=display:flex><span>    <span style=color:#75715e>###############</span>
</span></span><span style=display:flex><span>    w <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>rand(<span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>    least_false <span style=color:#f92672>=</span> _calc_false(w)
</span></span><span style=display:flex><span>    res <span style=color:#f92672>=</span> w
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> xrange(limit):
</span></span><span style=display:flex><span>        data <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>choice(datas)
</span></span><span style=display:flex><span>        t <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(w, data[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> np<span style=color:#f92672>.</span>sign(data[<span style=color:#ae81ff>1</span>]) <span style=color:#f92672>!=</span> np<span style=color:#f92672>.</span>sign(t):
</span></span><span style=display:flex><span>            t <span style=color:#f92672>=</span> w <span style=color:#f92672>+</span> data[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>*</span> data[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>            t_false <span style=color:#f92672>=</span> _calc_false(t)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            w <span style=color:#f92672>=</span> t
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> t_false <span style=color:#f92672>&lt;=</span> least_false:
</span></span><span style=display:flex><span>                least_false <span style=color:#f92672>=</span> t_false
</span></span><span style=display:flex><span>                res <span style=color:#f92672>=</span> t
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> res, least_false
</span></span></code></pre></div><h2 id=参考链接>参考链接</h2><p>本文主要参考了<a href=http://shaoxiongjiang.com/2013/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8-%E6%84%9F%E7%9F%A5%E5%99%A8-perceptron/ target=_blank rel=noopener>机器学习入门 - 感知器 (Perceptron)</a>和Wikipedia上面<a href=http://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 target=_blank rel=noopener>感知机</a>的词条。</p><p>以及<a href=https://class.coursera.org/ntumlone-001/class target=_blank rel=noopener>機器學習基石 (Machine Learning Foundations)</a>公开课的幻灯片。</p><h2 id=updated>Updated</h2><p>2013-12-8</p><p>修改了pocket-pla算法，提升了效率和准确性。</p><p>参考了<a href="https://class.coursera.org/ntumlone-001/forum/thread?thread_id=116#post-632" target=_blank rel=noopener>课程论坛</a>的讨论。并且感谢Li Tianyi同学指出我的问题。</p></div></div><footer class="py-3 mt-auto bg-light"><div class="container py-1 my-1"><div class="d-flex flex-wrap justify-content-between align-items-center"><p class="col-md mb-0 text-muted"></p><ul class="nav col-md-auto justify-content-end"></ul></div></div></footer><script src=/js/main.min.e8d88c82c0438b527f1aca4115652ba1e2877bf805b75593b23ac0e3fe2b3fe95a467d1feef275355132ba061da6404b0d24d55afabc209b294b1db043be014d.js integrity="sha512-6NiMgsBDi1J/GspBFWUroeKHe/gFt1WTsjrA4/4rP+laRn0f7vJ1NVEyugYdpkBLDSTVWvq8IJspSx2wQ74BTQ==" crossorigin=anonymous defer></script></body></html>
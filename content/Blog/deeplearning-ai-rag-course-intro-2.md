Title: Deeplearning.ai 《Retrieval-Augmented Generation (RAG)》课程导读（二）
Date: 2025-09-22 10:00
Tags: RAG, 信息检索, LLM, 检索增强生成
Slug: deeplearning-ai-rag-course-intro-2

[课程视频][1]

> 根据视频字幕生成，是给不想看视频的人准备的速读文档

## 简介

在实际生产环境中，信息检索理论需要与大规模数据处理结合。传统关系型数据库虽能支撑大部分基础检索，但当文档规模扩展至数百万甚至数十亿，尤其涉及语义搜索时，其性能会显著下降。

为此，我们需要**向量数据库**。它专为存储与检索海量向量而设计，几乎等同于 RAG（Retrieval-Augmented Generation）系统的底层设施。本模块的核心目标是：

* 理解为什么向量数据库在向量检索方面更优；
* 掌握多种搜索操作的执行方式；
* 学习在生产级 RAG 系统中常用的优化技术（文档分块、查询解析、结果重排序等）。

## ANN 算法

在语义搜索中，关键词匹配与向量相似度是基础。但若直接进行精确向量搜索，随着数据扩展，计算资源消耗与系统延迟会急剧增加。

* **k近邻（kNN）**：计算查询与所有文档向量的距离并排序，返回前 k 个邻居。直观但扩展性差，计算量随数据线性增长。
* **近似最近邻（ANN）**：通过牺牲精确度换取效率，保证结果“足够接近”。

典型方法：

1. **NSW（可导航小世界）**：构建邻近图，搜索从随机起点出发逐步靠近目标。速度快但可能错过全局最优。
2. **HNSW（分层 NSW）**：构建多层邻近图，从顶层到低层逐步收敛，时间复杂度近似对数级，能在十亿级规模下将延迟保持在几百毫秒。

三大特性总结：

1. 搜索速度远超精确 kNN；
2. 返回近似最优解；
3. 依赖高质量的图构建（预处理耗时但可离线完成）。

因此，ANN 是现代向量检索的核心基础。

## 向量数据库

**向量数据库（Vector Database）**专为高维向量的存储与 ANN 检索而设计，在语义搜索中优势明显。

核心优化：

* 高效构建邻近图（如 HNSW 索引）；
* 快速计算向量距离；
* 在大规模应用中保持高扩展性与低延迟。

典型产品：**Weaviate**（开源，支持本地与云端），同时市面上还有 Milvus、Pinecone 等。

操作流程：

1. **配置数据库**：连接或创建实例；
2. **准备数据**：生成稀疏向量（关键词搜索）和密集向量（语义搜索）；
3. **创建索引**：构建 ANN 所需结构；
4. **添加数据**：批量写入集合（如 *article*），自动生成语义向量并跟踪错误。

支持的检索类型：

* **向量搜索**（基于向量距离）；
* **关键词搜索**（BM25 倒排索引）；
* **混合搜索**（按权重结合语义与关键词结果）；
* **过滤查询**（属性条件筛选）。

流程总结：配置数据库 → 数据加载与索引 → 混合搜索 + 过滤。

## 文本分块技术

虽然向量数据库已对向量检索高度优化，但在生产环境中，**文本分块（chunking）**依然是必需步骤。

意义：

1. 嵌入模型有输入长度限制；
2. 分块能提升搜索相关性；
3. 仅将最相关片段传递给 LLM，节省上下文窗口。

问题：若知识库中只有整本书的嵌入，检索相关性差且上下文占用过大。通过分块，可生成数百万片段向量，数据库能高效存储与检索。

方法：

* **固定大小分块**：如 250 字符/块，设置 10% 重叠，避免截断语义。
* **递归字符切分**：优先按换行等标记切分，保持结构完整。
* **类型感知切分**：HTML 按标签，代码按函数，文本按段落等。

推荐默认方案：**每块约 500 字符，重叠 50–100 字符**。

## 高级分块技术

基础分块可能破坏语义，因此出现了高级方法：

1. **语义分块**：逐句向量化，若与前块相似度高则合并，否则切分。优点是块更符合语义转折，缺点是计算量大。
2. **LLM 分块**：用语言模型直接根据语义和主题切分，黑箱但效果好，随着模型成本下降越来越可行。
3. **上下文感知分块（chunk enrichment）**：为每块生成摘要或上下文说明并与其一同嵌入，提升检索与生成效果。

结论：多数系统使用固定或递归切分，语义/LLM 分块适合高质量场景；上下文感知分块可与任意方法叠加，常带来双重收益。

## 查询语句解析

用户查询往往模糊或冗余，直接送入数据库效果差，因此需做**查询解析**。

常见方法：

* **查询重写**（推荐优先）：利用 LLM 将冗长自然语言转为结构化检索友好语句，常显著提升效果。
* **命名实体识别（NER）**：抽取地点、人名、日期等实体，用于元数据过滤。
* **假设文档嵌入（HIDE）**：生成理想搜索结果的假设文档，嵌入后与知识库匹配。

经验：多数场景下，**查询重写**是性价比最高的必选步骤；NER 和 HIDE 更适合特定高精度场景。

## 交叉编码器与 ColBERT

三类语义检索架构：

* **基础编码器（bi-encoder）**：查询与文档分别嵌入，依赖向量数据库搜索，速度快、存储小，但语境交互有限。
* **交叉编码器（cross-encoder）**：提示与文档拼接输入模型，直接输出相关性分数，质量最佳但极慢，仅适合重排序。
* **ColBERT**：文档与查询逐词嵌入，评分时逐词匹配相加，兼具交互性与效率，但存储需求极大。

结论：

* 默认用 bi-encoder；
* 重排序用 cross-encoder；
* 高精度场景（法律、医疗）可采用 ColBERT。

## 检索结果重排序

**重排序（reranking）**是在初始检索后、送入 LLM 前进行的关键步骤。

流程：

1. 初始检索返回 20–100 个候选；
2. 用交叉编码器或 LLM 对候选重新打分；
3. 最终选取 5–10 个结果。

优势：既利用 ANN 的高效性，又保证结果质量，显著提升相关性。

工程实现：在大多数框架中，只需为查询添加参数即可启用重排序，改造成本低。实践表明，这是优化 RAG 时最值得优先尝试的手段之一。


## 总结

本模块内容涵盖了从算法原理到生产优化的完整路径：

* **ANN 算法**：以近似解换取高效搜索；
* **向量数据库**：为高维向量检索而生，支撑大规模 RAG 系统；
* **优化技术**：

  * 文档分块：更细粒度语义捕捉 + 上下文节省；
  * 查询解析：让自然语言提示更适配检索；
  * 重排序：用强模型精修候选结果。

这些方法常与混合搜索组合使用，是大多数生产级系统的标准做法。进阶方法（语义分块、LLM 分块、HIDE 等）则适合在验证效果后引入。

最终，学习者将把这些知识整合进完整的 RAG 系统，掌握从**基础检索到性能优化**的全链路技能。下一模块将转向 RAG 的另一核心：**大语言模型**，探索如何在检索结果基础上生成更优答案。



[1]: https://www.bilibili.com/video/BV1QRbnzTEyK?spm_id_from=333.788.videopod.episodes&vd_source=dbe2034ffbdf969aa84f0fa33428b1ae

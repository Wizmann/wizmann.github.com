Title: Deeplearning.ai 《Retrieval-Augmented Generation (RAG)》课程导读（三）
Date: 2025-09-24 10:00
Tags: RAG, 信息检索, LLM, 检索增强生成
Slug: deeplearning-ai-rag-course-intro-3

[源视频][1]

> 根据视频字幕生成，是给不想看视频的人准备的速读文档

## LLM 简介

RAG 系统由检索器和 LLM 两部分组成。检索器负责找到信息，但真正决定回答效果的，是 LLM。

在这一部分，学习目标包括：

* 理解 LLM 的工作原理；
* 掌握提升性能的方法；
* 熟悉 Transformer 架构；
* 学习如何在代码中调用 LLM，并逐步改进；
* 探索一些高级技术和实用建议。

完成后，你将能亲手构建一个小型 RAG 系统。

## Transformer 架构

### 起源

Transformer 架构来自 2017 年的论文 **《Attention Is All You Need》**。它最初用于机器翻译，由编码器和解码器组成。如今大多数语言模型使用解码器，嵌入模型使用编码器。

### 输入处理

1. 分词：输入文本切分成 token；
2. 嵌入：每个 token 转换成向量；
3. 位置编码：加入顺序信息；
4. 注意力机制：token 之间相互“关注”，捕捉关联；
   * 多头注意力可以从不同角度建模关系；
5. 前馈层：大量参数更新向量；
6. 堆叠：多层重复这些步骤，逐渐提升理解。

### 文本生成

* 模型基于向量预测下一个 token 的概率分布；
* 按概率抽样生成 token；
* 将新 token 加回输入，重复处理；
* 直到生成结束符或达到长度限制。

### 与 RAG 的关系

* 注意力机制让模型能理解注入的检索信息；
* 生成存在随机性，可能与检索内容不一致；
* 计算开销大，是 RAG 成本的主要来源。

## LLM 采样策略

LLM 每一步生成 token 都是从概率分布中随机选择。控制随机性很重要。

常见方法：

* **贪心解码**：总选最高概率 → 稳定但僵化；
* **温度（Temperature）**：调节分布尖锐度，低温度更确定，高温度更随机；
* **Top-K**：从前 K 个候选中选；
* **Top-P（核采样）**：从累计概率 ≤ P 的候选集中选；
* **重复惩罚**：降低重复 token 的概率；
* **对数偏差（Logit Bias）**：人为调整特定 token 的概率。

推荐默认配置：

* 温度 = 0.8
* Top-P = 0.9
* 重复惩罚 = 1.2

应用场景：

* **低温度 + 低 Top-P**：适合代码、事实类任务；
* **高温度 + 高 Top-P**：适合写作、开放问题。

## 模型选择方法

选择模型会影响速度、质量和成本。

### 主要指标

* 参数规模：1–100 亿为小模型，100–500 亿为大模型；
* 成本：按百万 token 计价；
* 上下文窗口：可处理的最大输入输出长度；
* 延迟与速度：响应和生成速度；
* 知识截止日期：越新越好。

### 评估方式

* 自动化基准：如 MMLU、编程测试；
* 人工评估：如 LM Arena，基于 Elo 排名；
* 模型评估模型（LLM-as-a-judge）：需注意偏差。

方法论：先用量化指标缩小范围，再用质量评估确认。保持灵活，方便更新替换。

## 提示词工程（基础）

提示词通常包含：

* 系统提示（设定语气和规则）；
* 历史对话；
* 检索结果；
* 用户输入。

RAG 中常用提示模板，把这些要素固定下来，方便实验和改进。

## 提示词工程（高级）

常见技术：

* **上下文学习（ICL）**：在提示中加入示例（one-shot / few-shot）；
* **推理导向提示**：
  * Scratchpad：先推理再回答；
  * Chain-of-Thought：逐步推理；
  * 推理模型：自带推理能力，成本更高；
* **上下文管理**：对话过长时进行摘要或剪枝，避免占满上下文窗口。

## 幻觉处理

幻觉指模型生成的虚假信息。常见类型：

* 轻微错误（数值说错）；
* 否认真实事实；
* 编造不存在的信息。

应对方法：

* 在系统提示中要求模型只基于检索结果回答，并引用来源；
* 使用 Context Cite 等工具验证回答与文档的对应关系；
* 用 ALCE 基准测试幻觉率和引用质量。

## 性能评估

评估的目标是量化 LLM 在 RAG 中的表现。

常用指标：

* **相关性**：回答是否满足用户需求；
* **可信度**：回答是否由检索文档支持；
* **其他指标**：如引用准确性、抗干扰性（Ragas 库提供）。

还可以结合：

* 用户反馈（点赞/点踩）；
* A/B 测试（对比不同模型或参数）。

建议：结合自动化评估和人工反馈。

## 自主式 RAG

自主式 RAG 使用多个模型协作，而不是一个模型完成所有步骤。

常见工作流：

* 顺序工作流：按步骤依次完成；
* 条件工作流：由路由模型决定是否检索或走哪条路径；
* 迭代工作流：不断尝试直到合格；
* 并行工作流：多个模型并行处理，再合并结果。

优势：

* 小模型负责简单任务（高效低成本）；
* 大模型负责复杂生成；
* 专用模型负责引用或验证。

## 总结

这一部分课程带来的主要收获：

* 理解 Transformer 架构和 LLM 的工作机制；
* 掌握采样策略，能控制输出的稳定性与多样性；
* 学会如何在成本、速度、质量之间选择合适的模型；
* 掌握提示工程的基本与高级方法；
* 了解幻觉的成因与缓解方式；
* 学习性能评估方法；
* 认识多模型协作的自主式 RAG 思路。

这些内容组成了构建和优化 RAG 系统的完整知识框架，也为将原型发展为生产系统奠定了基础。


[1]: https://www.bilibili.com/video/BV1QRbnzTEyK?spm_id_from=333.788.videopod.episodes&vd_source=dbe2034ffbdf969aa84f0fa33428b1ae

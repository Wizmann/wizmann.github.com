<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Distributed System on Maerlyn's Rainbow</title><link>https://wizmann.top/tags/distributed-system/</link><description>Recent content in Distributed System on Maerlyn's Rainbow</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Wed, 27 Dec 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://wizmann.top/tags/distributed-system/index.xml" rel="self" type="application/rss+xml"/><item><title>[tl;dr] 论文阅读：Borg - Large-scale cluster management at Google</title><link>https://wizmann.top/posts/tl-dr-borg/</link><pubDate>Wed, 27 Dec 2023 00:00:00 +0000</pubDate><guid>https://wizmann.top/posts/tl-dr-borg/</guid><description>&lt;ul>
&lt;li>
&lt;h2 id="系统概览">系统概览 &lt;a href="#%e7%b3%bb%e7%bb%9f%e6%a6%82%e8%a7%88" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>Borg是谷歌开发的一种高效的集群管理系统，旨在优化资源利用率和提高系统的可靠性及可用性
&lt;ul>
&lt;li>隐藏资源管理细节与故障处理，允许用户专注于应用程序的开发&lt;/li>
&lt;li>保证非常高的可靠性和可用性，以支持用户应用程序的高可靠性和高可用性&lt;/li>
&lt;li>支持运行来自众多应用的数十万个作业，并高效运行于数以万计的机器上&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h2 id="用户视角">用户视角 &lt;a href="#%e7%94%a8%e6%88%b7%e8%a7%86%e8%a7%92" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>用户通过定义&lt;em>job&lt;/em>和&lt;em>task&lt;/em>与Borg进行交互
&lt;ul>
&lt;li>一个&lt;em>job&lt;/em>由运行相同程序的一个或多个&lt;em>task&lt;/em>组成&lt;/li>
&lt;li>每一个&lt;em>job&lt;/em>运行于一个&lt;em>Borg cell&lt;/em>（单元）之中，&lt;em>cell&lt;/em>是一组机器的集合，是Borg管理的基本单元&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Borg的工作负载
&lt;ul>
&lt;li>长期运行的时延敏感型服务&lt;/li>
&lt;li>批处理作业&lt;/li>
&lt;li>运行在实体机上，避免VM的虚拟化开销&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;em>Allocs&lt;/em>
&lt;ul>
&lt;li>预留给一项或多项任务的一组资源&lt;/li>
&lt;li>&lt;em>Alloc&lt;/em>可以将不同 &lt;em>jobs&lt;/em> 的 &lt;em>tasks&lt;/em> 聚集到同一台机器上&lt;/li>
&lt;li>如果一个 &lt;em>alloc&lt;/em> 必须重新分配到另外一台主机，属于它的 &lt;em>task(s)&lt;/em> 也会同它一起重新被调度&lt;/li>
&lt;li>一旦创建一个 &lt;em>alloc&lt;/em> 集合，就可以提交一个或多个 jobs 运行其中&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>命名服务和监控
&lt;ul>
&lt;li>Borg包含一个稳定的 &lt;em>Borg命名服务&lt;/em> (BNS)，包括 cell 名，job 名和 task id&lt;/li>
&lt;li>Borg将 &lt;em>task&lt;/em> 的主机名和端口写入 Chubby，用于 RPC 系统查找 task endpoint&lt;/li>
&lt;li>Borg还会将 &lt;em>job&lt;/em> size与其运行状态写入Chubby，便于load balancer平衡流量&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h2 id="borg的架构">Borg的架构 &lt;a href="#borg%e7%9a%84%e6%9e%b6%e6%9e%84" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>&lt;em>Borgmaster&lt;/em>
&lt;ul>
&lt;li>主管理进程
&lt;ul>
&lt;li>逻辑上的“单点”，有5个在线备份，使用Paxos选举master&lt;/li>
&lt;li>状态存储在内存中，并且备份在高可靠性的Paxos存储中&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>调度进程
&lt;ul>
&lt;li>可行性检查
&lt;ul>
&lt;li>用于找到满足任务约束、具备足够可用资源的一组机器&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>打分（scoring）
&lt;ul>
&lt;li>在“可行机器”中根据用户偏好，为机器打分&lt;/li>
&lt;li>打分策略
&lt;ul>
&lt;li>worst fit（E-PVN的变种）会将任务分散到不同的机器上
&lt;ul>
&lt;li>有余量应对流量的尖峰&lt;/li>
&lt;li>会导致资源的碎片化，阻碍大型&lt;em>task&lt;/em>的部署&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>best fit，会尽量“紧凑”的使用机器，以减少资源碎片
&lt;ul>
&lt;li>便于大型&lt;em>task&lt;/em>的部署&lt;/li>
&lt;li>错误的资源估计会被“惩罚”，尤其影响突发的负载&lt;/li>
&lt;li>影响利于富裕计算资源的batch jobs&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>混合模型，尽量减少“受困资源”，即因为其它资源被完全占用而无法分配出去的资源&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>优化
&lt;ul>
&lt;li>启动时间优化
&lt;ul>
&lt;li>中位数启动时间为25s，80%用于安装相关依赖&lt;/li>
&lt;li>将相关&lt;em>task&lt;/em>优先分配到拥有相关依赖的机器上&lt;/li>
&lt;li>使用 &lt;em>tree-like&lt;/em> 或 &lt;em>torrent-like&lt;/em> 机制，并发的分发相关依赖&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>计算开销优化
&lt;ul>
&lt;li>使得Borg能管理更多的机器&lt;/li>
&lt;li>打分缓存：将可行性检查和打分结果缓存&lt;/li>
&lt;li>等价类：同一 &lt;em>job&lt;/em> 中的 &lt;em>task&lt;/em> 通常具有类似的约束，因此可以将多个任务视为一个等价类&lt;/li>
&lt;li>松弛随机化：计算所有机器的可行性和得分代价太高，可以随机取样一批机器，然后选择其中一个“足够好”的机器&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;em>Borglet&lt;/em>
&lt;ul>
&lt;li>&lt;em>Borglet&lt;/em> 是运行在每台机器上的本地代理，管理本地的任务和资源&lt;/li>
&lt;li>&lt;em>Borgmaster&lt;/em> 会周期性地向每一个Borglet拉取当前状态，易于控制通信速度，避免“恢复风暴”&lt;/li>
&lt;li>为了性能可扩展性，每个Borgmaster副本会运行无状态的 &lt;em>link shard&lt;/em> 去处理与部分Borglet通信
&lt;ul>
&lt;li>当 &lt;em>Borgmaster&lt;/em> 重新选举时，&lt;em>link shard&lt;/em> 会重新划分分区&lt;/li>
&lt;li>&lt;em>link shard&lt;/em> 会聚合和压缩信息，仅仅向被Borgmaster报告状态的更新，以此减少更新负载&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>如果 &lt;em>Borglet&lt;/em> 多轮没有响应资源查询，则会被标记为down。运行其上的任务会被重新调度到其他机器。如果恢复通信，则 &lt;em>Borgmaster&lt;/em> 会通知 &lt;em>Borglet&lt;/em> 杀死已经重新调度的任务，以此保证任务的唯一性&lt;/li>
&lt;li>Borglet与Borgmaster失去联系时，仍会继续处理相关任务。以应对 &lt;em>Borgmaster&lt;/em> 的暂时失效&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h2 id="可靠性">可靠性 &lt;a href="#%e5%8f%af%e9%9d%a0%e6%80%a7" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>自动重新调度器被驱逐的任务&lt;/li>
&lt;li>将任务分散到不同的失败域中&lt;/li>
&lt;li>限制一个作业中同时失败任务的个数和中断率&lt;/li>
&lt;li>使用声明式的期望状态表示和幂等的变更操作，以便无害地重新提交请求&lt;/li>
&lt;li>对于机器级别的失效，限制其重新调度的速率，因为难以区分大规模机器故障和网络分区&lt;/li>
&lt;li>避免重试引发错误的&amp;lt;任务-机器&amp;gt;匹配对&lt;/li>
&lt;li>关键数据持久化，写入磁盘&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h2 id="资源利用和效率">资源利用和效率 &lt;a href="#%e8%b5%84%e6%ba%90%e5%88%a9%e7%94%a8%e5%92%8c%e6%95%88%e7%8e%87" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>评估方法
&lt;ul>
&lt;li>&lt;em>cell compaction&lt;/em>：通过移除机器来找出给定工作负载能适应的最小的单元大小，然后反复从头开始重新打包工作负载，以确保不会因错误的配置而陷入困境&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>“单元共享”：在同一台机器上运行生产任务和非生产任务，以优化资源使用
&lt;ul>
&lt;li>实验表明，共享资源会影响实际的CPU计算性能&lt;/li>
&lt;li>但是在节约成本的巨大优势上面，CPU性能的退化是可以容忍的&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>“大型单元”：允许超大型计算任务，减少任务的碎片化&lt;/li>
&lt;li>细粒度资源请求
&lt;ul>
&lt;li>以千分之一的CPU核，和内存、磁盘的字节数为资源请求的最小单元&lt;/li>
&lt;li>相比预设资源分配（套餐），可以避免额外的资源开销&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>资源回收
&lt;ul>
&lt;li>对于可以容忍低质量资源的工作（例如批处理作业），Borg会评估任务将使用的资源，并回收空闲资源&lt;/li>
&lt;li>最初的预留值与其资源请求一致，然后300秒之后，会慢慢降低到实际使用率外加一个安全边缘&lt;/li>
&lt;li>如果利用率超过资源预留值，预留值会快速增长。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h2 id="隔离与安全性">隔离与安全性： &lt;a href="#%e9%9a%94%e7%a6%bb%e4%b8%8e%e5%ae%89%e5%85%a8%e6%80%a7" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>安全隔离
&lt;ul>
&lt;li>使用Linux chroot jail在共享同一台机器的任务之间确保安全性&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>性能隔离
&lt;ul>
&lt;li>基于cgroup的资源容器，允许详细的资源核算并执行限制，防止任务相互干扰，确保稳定和可预测的性能&lt;/li>
&lt;li>使用&lt;em>appclass&lt;/em>，尽可能保证延迟敏感服务的资源使用&lt;/li>
&lt;li>区分&lt;em>可压缩资源&lt;/em> 和 &lt;em>不可压缩资源&lt;/em>
&lt;ul>
&lt;li>可压缩资源（compressiable） - CPU%和Disk IO，可以暂时限流&lt;/li>
&lt;li>不可压缩资源（non-compressible） - 内存、磁盘占用，需要清除优先级低的线程&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>内核的CPU调度器，允许根据每个资源容器的负载状况来动态决定是否要驱逐低优先级任务，同时避免多个高优先级任务在一个cpu上争抢
&lt;ul>
&lt;li>仍在尝试cpu调度时更好的考虑线程亲和、NUMA亲和等策略&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h2 id="经验教训">经验教训： &lt;a href="#%e7%bb%8f%e9%aa%8c%e6%95%99%e8%ae%ad" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>
&lt;h3 id="负面经验">负面经验 &lt;a href="#%e8%b4%9f%e9%9d%a2%e7%bb%8f%e9%aa%8c" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>&lt;em>Job&lt;/em>作为&lt;em>Task&lt;/em>的唯一分组机制的局限性
&lt;ul>
&lt;li>缺乏将整个多&lt;em>Job&lt;/em>服务作为单一实体进行管理，或引用服务相关&lt;em>Job&lt;/em>（如Canary与Prod滚动更新）的方式&lt;/li>
&lt;li>用户会在&lt;em>Job&lt;/em>名称中编入拓扑，并构建外部管理工具来解析这些名称，这导致了滚动更新和作业调整大小等问题的不灵活语义&lt;/li>
&lt;li>Kubernetes通过使用标签组织其调度单元（Pods），提供了更多灵活性&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>单个IP地址带来的复杂性
&lt;ul>
&lt;li>同一台机器上的所有任务共享该机器的单个IP地址和端口空间&lt;/li>
&lt;li>导致端口也成为一种资源，在调度时候需要被考虑&lt;/li>
&lt;li>Kubernetes采用了更友好的方法，每个Pod和服务都获取自己的IP地址，从而简化了这些复杂性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>偏向于高级用户
&lt;ul>
&lt;li>Borg提供了一整套面向“高级用户”的功能，允许他们细致调整程序运行方式&lt;/li>
&lt;li>这种API的丰富性使得对于“普通”用户更加困难，并限制了其演变&lt;/li>
&lt;li>Google构建了自动化工具，对于允许“失败”的应用程序，通过实验来探测适当配置&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="积极经验">积极经验 &lt;a href="#%e7%a7%af%e6%9e%81%e7%bb%8f%e9%aa%8c" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>Allocs是有用的
&lt;ul>
&lt;li>Kubernetes中的Alloc等效物是Pod，它是一个资源包，用于一个或多个容器，总是被调度到同一台机器上并可以共享资源&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>集群管理不仅是任务管理
&lt;ul>
&lt;li>尽管Borg的主要角色是管理任务和机器的生命周期，但运行在Borg上的应用程序从许多其他集群服务中受益，包括命名和负载均衡&lt;/li>
&lt;li>Kubernetes使用服务抽象支持命名和负载均衡，服务有一个名称和一组由标签选择器定义的动态Pods。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>自省至关重要
&lt;ul>
&lt;li>尽管Borg几乎总是“运行良好”，但当出现问题时，找到根本原因可能具有挑战性&lt;/li>
&lt;li>Borg的重要设计决策之一是向所有用户展示调试信息&lt;/li>
&lt;li>Kubernetes旨在复制Borg的许多内省技术，例如，它配备了cAdvisor等工具进行资源监控和基于Elasticsearch/Kibana和Fluentd的日志聚合&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>主控节点是分布式系统的核心
&lt;ul>
&lt;li>Borgmaster最初被设计为一个单体系统，但随着时间的推移，它变得更像是一个内核，位于协作管理用户作业的一系列服务的中心&lt;/li>
&lt;li>Kubernetes架构更进一步，它有一个核心的API服务器，仅负责处理请求和操纵底层状态对象，集群管理逻辑被构建为小型可组合的微服务，这些服务是这个API服务器的客户端​​&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/">论文&lt;/a>&lt;/li>
&lt;/ul>
&lt;div class="alert alert-info" role="alert">本文部分内容由ChatGPT4生成&lt;/div></description></item><item><title>[tl;dr] 论文阅读：Rarest First and Choke Algorithms Are Enough</title><link>https://wizmann.top/posts/tl-dr-rarest-first-and-choke-algorithms-are-enough/</link><pubDate>Fri, 08 Dec 2023 00:00:00 +0000</pubDate><guid>https://wizmann.top/posts/tl-dr-rarest-first-and-choke-algorithms-are-enough/</guid><description>&lt;ul>
&lt;li>
&lt;h2 id="基本概念">基本概念 &lt;a href="#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>&lt;strong>Peer&lt;/strong>：BitTorrent P2P下载的参与者&lt;/li>
&lt;li>&lt;strong>Leecher&lt;/strong>：“吸血者”，仍在下载过程中的peer&lt;/li>
&lt;li>&lt;strong>Seeder&lt;/strong>：做种者，下载完成后还在继续做种的peer&lt;/li>
&lt;li>&lt;strong>Piece&lt;/strong>：Piece是文件的数据单元。当文件被分享时，它被分割成多个大小相等的片段，称为&amp;quot;pieces&amp;quot;。这些pieces是peer间传输的基本单位&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h2 id="最稀有优先算法rarest-first-algorithm">&amp;ldquo;最稀有优先算法&amp;rdquo;（Rarest First Algorithm） &lt;a href="#%e6%9c%80%e7%a8%80%e6%9c%89%e4%bc%98%e5%85%88%e7%ae%97%e6%b3%95rarest-first-algorithm" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>&amp;ldquo;最稀有优先算法&amp;rdquo;（Rarest First Algorithm）是BitTorrent协议中的一个关键策略，用于决定哪些数据块（piece）首先被下载和分享。这个算法的核心目标是优化整个网络中数据的分布，确保更快的下载速度和更高的效率。&lt;/li>
&lt;li>
&lt;h3 id="基本原理">基本原理 &lt;a href="#%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>&lt;strong>数据块的稀有度&lt;/strong>
&lt;ul>
&lt;li>在BitTorrent网络中，文件被分割成许多小的数据块。
&lt;ul>
&lt;li>“最稀有优先”算法的目的是优先下载那些网络中数量最少的数据块。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>选择下载的块&lt;/strong>：
&lt;ul>
&lt;li>当一个peer加入Torrent网络，并开始下载文件时，它首先会从所有连接的peer那里获取有关哪些数据块是稀有的信息。
&lt;ul>
&lt;li>然后，它优先请求下载那些最稀有的数据块。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>动态调整&lt;/strong>：
&lt;ul>
&lt;li>随着下载的进行，每个peer会不断更新和重新评估网络中每个数据块的稀有度，并相应地调整其下载优先级。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="算法的重要性">算法的重要性 &lt;a href="#%e7%ae%97%e6%b3%95%e7%9a%84%e9%87%8d%e8%a6%81%e6%80%a7" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>&lt;strong>提高效率&lt;/strong>：通过优先下载最稀有的块，这个算法帮助加快了文件的整体下载速度。一旦最稀有的块被更多peer获取，它们就更容易被进一步分享和分发。&lt;/li>
&lt;li>&lt;strong>防止瓶颈&lt;/strong>：如果没有这个算法，某些数据块可能会变得很难获得，导致下载过程在接近完成时放慢，这被称为“最后一块问题”（Last Piece Problem）。&lt;/li>
&lt;li>&lt;strong>促进平等分享&lt;/strong>：这种方法鼓励peer分享它们拥有的稀有块，从而提高了整个网络中的合作和资源共享。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="实际应用">实际应用 &lt;a href="#%e5%ae%9e%e9%99%85%e5%ba%94%e7%94%a8" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>在BitTorrent网络中，这个算法对于确保高效的数据分发至关重要。它不仅提高了单个用户的下载速度，而且还提高了整个网络的效率，确保了资源在用户之间的均衡分配。通过这种方式，BitTorrent网络能够有效地避免瓶颈和提高数据的可用性，即使在面对大量用户的情况下也是如此。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="结论">结论 &lt;a href="#%e7%bb%93%e8%ae%ba" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>最稀有优先算法是BitTorrent网络高效运行的关键组成部分。它通过智能地选择下载和分享网络中最稀有的数据块，提高了资源的整体分布和可用性，确保了快速、平衡的文件共享。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h2 id="窒息算法choking-algorithm">&amp;ldquo;窒息算法&amp;rdquo;（Choking Algorithm） &lt;a href="#%e7%aa%92%e6%81%af%e7%ae%97%e6%b3%95choking-algorithm" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>&amp;ldquo;窒息算法&amp;rdquo;（Choking Algorithm）是BitTorrent协议中的一个关键组成部分，用于管理多个peer之间的数据传输。这个算法帮助优化带宽的使用，确保网络中的资源被高效合理地分配。其核心目的是促进peer间的合作和数据的快速分发。&lt;/li>
&lt;li>
&lt;h3 id="窒息算法的基本原理">窒息算法的基本原理 &lt;a href="#%e7%aa%92%e6%81%af%e7%ae%97%e6%b3%95%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>&lt;strong>选择和窒息（Choking and Unchoking）&lt;/strong>
&lt;ul>
&lt;li>在BitTorrent网络中，每个peer同时维护着一组“窒息”（choked）和“未窒息”（unchoked）的peer名单。
&lt;ul>
&lt;li>被“窒息”的peer无法从窒息方接收文件数据，而“未窒息”的peer可以进行数据交换。&lt;/li>
&lt;li>这种状态是动态的，peer根据算法定期更新它们的窒息/未窒息peer名单。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>利益驱动的决策&lt;/strong>
&lt;ul>
&lt;li>算法核心是“利益驱动”（tit-for-tat）策略，即peer更倾向于向那些能给它提供数据的peer提供数据。
&lt;ul>
&lt;li>这种方法鼓励peer分享数据，因为分享越多，获得数据的机会也越大。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>优化器&lt;/strong>：
&lt;ul>
&lt;li>除了基于交换数据的量来决定窒息状态外，大多数BitTorrent客户端还实现了一个“优化器”（Optimizer），用于探索新的peer。
&lt;ul>
&lt;li>通常，这是通过定期“未窒息”一个随机选择的peer来实现的，即使它在过去的数据交换中表现不佳或没有数据交换。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>窒息周期&lt;/strong>：
&lt;ul>
&lt;li>peer定期评估其连接，并根据从其他peer接收到的数据速率来更新其窒息/未窒息名单&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="窒息算法的重要性">窒息算法的重要性 &lt;a href="#%e7%aa%92%e6%81%af%e7%ae%97%e6%b3%95%e7%9a%84%e9%87%8d%e8%a6%81%e6%80%a7" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>&lt;strong>合作促进&lt;/strong>：通过奖励那些分享资源的peer，窒息算法鼓励合作，提高了网络中的资源共享效率。&lt;/li>
&lt;li>&lt;strong>防止自私行为&lt;/strong>：算法减少了自私peer（只下载不上传的）的优势，因为这些peer不太可能被其他peer“未窒息”。&lt;/li>
&lt;li>&lt;strong>网络拥塞控制&lt;/strong>：它帮助控制网络拥塞，通过限制peer的连接数量和数据传输，优化带宽使用。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="结论-1">结论 &lt;a href="#%e7%bb%93%e8%ae%ba-1" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>窒息算法是BitTorrent协议高效性的关键，它通过一种简单但有效的方式来鼓励数据共享和合作，保证了整个网络的健康和高效运行。通过这种动态的窒息/未窒息机制，BitTorrent网络能够有效地管理带宽和连接，确保资源在网络中的快速且公平的分配。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h2 id="为什么说已经足够了">为什么说“已经足够了” &lt;a href="#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%af%b4%e5%b7%b2%e7%bb%8f%e8%b6%b3%e5%a4%9f%e4%ba%86" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>
&lt;blockquote>
&lt;p>因为这是一门实验科学&lt;/p>&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;h3 id="最稀有优先算法rarest-first-algorithm-1">&amp;ldquo;最稀有优先算法&amp;rdquo;（Rarest First Algorithm） &lt;a href="#%e6%9c%80%e7%a8%80%e6%9c%89%e4%bc%98%e5%85%88%e7%ae%97%e6%b3%95rarest-first-algorithm-1" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>
&lt;h3 id="种子的熵">种子的熵 &lt;a href="#%e7%a7%8d%e5%ad%90%e7%9a%84%e7%86%b5" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>描述了种子中各个数据块在所有peer间的分布情况&lt;/li>
&lt;li>高熵意味着数据块在所有peer中分布得很均匀，peer之间更有可能拥有彼此尚未下载的块&lt;/li>
&lt;li>高熵的种子通常意味着更高的数据交换效率&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="理想熵ideal-entrophy">理想熵（Ideal Entrophy） &lt;a href="#%e7%90%86%e6%83%b3%e7%86%b5ideal-entrophy" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>是指网络中的数据块（pieces）在所有leechers之间均匀分布&lt;/li>
&lt;li>每个leechers都持有一些其他leechers需要的数据块，从而确保了网络中的每个leechers都对其他leechers感兴趣。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="冷启动transient-state">冷启动（Transient State） &lt;a href="#%e5%86%b7%e5%90%af%e5%8a%a8transient-state" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>当种子刚开始传播时的动态，优先传播稀有块，提高下载效率&lt;/li>
&lt;li>Rarest First Algorithm解决了种子的冷启动问题，确保了最不常见的块被优先传播，提高了整个网络的下载效率&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="稳定态steady-state">稳定态（Steady State） &lt;a href="#%e7%a8%b3%e5%ae%9a%e6%80%81steady-state" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>网络中的大部分块已经被比较均匀地传播。最稀有优先算法在这一阶段继续确保数据块的多样性，从而减少了任何特定块成为瓶颈的可能性&lt;/li>
&lt;li>算法鼓励peer间的有效合作，因为每个peer都可能持有其他peer需要的稀有块&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="最后一块问题last-pieces-problem">“最后一块”问题（Last Pieces Problem） &lt;a href="#%e6%9c%80%e5%90%8e%e4%b8%80%e5%9d%97%e9%97%ae%e9%a2%98last-pieces-problem" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>下载接近完成时，某些块变得非常稀有，从而延缓整个下载过程&lt;/li>
&lt;li>算法确保即使在下载的后期，所有参与的peer仍然有激励去交换彼此之间缺少的块&lt;/li>
&lt;li>避免了下载末期的稀有块瓶颈&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="窒息算法choking-algorithm-1">&amp;ldquo;窒息算法&amp;rdquo;（Choking Algorithm） &lt;a href="#%e7%aa%92%e6%81%af%e7%ae%97%e6%b3%95choking-algorithm-1" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>
&lt;h3 id="对等原则tit-for-tat-fairness">“对等原则”（Tit-for-tat Fairness） &lt;a href="#%e5%af%b9%e7%ad%89%e5%8e%9f%e5%88%99tit-for-tat-fairness" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>如果A从B下载的数据少于B从A下载的数据，A会拒绝继续与B分享数据&lt;/li>
&lt;li>用来保证公平性，杜绝free rider&lt;/li>
&lt;li>在动态或非对称网络环境中可能效率低下&lt;/li>
&lt;li>会导致网络空闲资源的浪费&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="旧版窒息算法">旧版窒息算法 &lt;a href="#%e6%97%a7%e7%89%88%e7%aa%92%e6%81%af%e7%ae%97%e6%b3%95" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>旧版窒息算法只考虑了peer之间的下载速度，而不是它们的上传贡献
&lt;ul>
&lt;li>少量上传速度快的leecher会占据大量带宽，不利于种子熵的增加&lt;/li>
&lt;li>下载速度快的free riders得到了比实际贡献更多的回报&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>基于更宏观的性能指标（如整体上传贡献）的策略能够更好地适应这些变化&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;h3 id="新版窒息算法">新版窒息算法 &lt;a href="#%e6%96%b0%e7%89%88%e7%aa%92%e6%81%af%e7%ae%97%e6%b3%95" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>上传速度快的leecher一定比上传速度慢的leecher获得更多的下载速度，保证了近似的对等原则&lt;/li>
&lt;li>对于seed（做种者）而言，应该对每个leecher提供相同的服务时间。保证了网络中的公平性和效率&lt;/li>
&lt;li>因为文件块可以被更平均的分配给了其它peer，在冷启动时的弹性更强，对于free riders的抵抗性也更强&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Link
&lt;ul>
&lt;li>&lt;a href="http://conferences.sigcomm.org/imc/2006/papers/p20-legout.pdf">Rarest First and Choke Algorithms Are Enough&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="alert alert-info" role="alert">本文部分内容由ChatGPT4生成&lt;/div></description></item><item><title>Introduction to Ceph</title><link>https://wizmann.top/posts/introduction-to-ceph/</link><pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate><guid>https://wizmann.top/posts/introduction-to-ceph/</guid><description>&lt;h2 id="什么是ceph">什么是Ceph &lt;a href="#%e4%bb%80%e4%b9%88%e6%98%afceph" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>Ceph是一个可扩展的，高性能的分布式存储系统。提供了三种不同类型的接口以适应不同的应用场景：&lt;/p>
&lt;ul>
&lt;li>block-based: 块存储，可以用做VM的虚拟磁盘&lt;/li>
&lt;li>object-based: 对象存储，与Amazon S3等常用对象存储兼容&lt;/li>
&lt;li>file system: POSIX兼容的分布式文件系统，可以被本地系统挂载，并且能被多个客户端共享&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://raw.githubusercontent.com/Wizmann/assets/master/wizmann-pic/20-11-28/2020-11-28_22-04-49.png" alt="">&lt;/p>
&lt;h3 id="ceph的特性">Ceph的特性 &lt;a href="#ceph%e7%9a%84%e7%89%b9%e6%80%a7" class="anchor">🔗&lt;/a>&lt;/h3>&lt;p>由于采用了CRUSH算法，Ceph有着优异的可扩展性（宣称可以无限扩展）。并且借助可扩展性，进而实现高性能、高可靠性和高可用性。&lt;/p>
&lt;p>Ceph是一个去中心化的存储系统，无需中心节点进行资源的管理与调度，全部的管理功能由存储节点自治完成。使得整个系统可以自我管理与自我恢复，减少运维成本与管理成本。&lt;/p>
&lt;h2 id="rados---ceph的存储引擎">RADOS - Ceph的存储引擎 &lt;a href="#rados---ceph%e7%9a%84%e5%ad%98%e5%82%a8%e5%bc%95%e6%93%8e" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>RADOS=Reliable Autonomic Distributed Object Store。RADOS是Ceph底层的存储引擎，所有的接口都建立在RADOS的功能之上。&lt;/p>
&lt;h3 id="rados中的存储结构">RADOS中的存储结构 &lt;a href="#rados%e4%b8%ad%e7%9a%84%e5%ad%98%e5%82%a8%e7%bb%93%e6%9e%84" class="anchor">🔗&lt;/a>&lt;/h3>&lt;p>&lt;img src="https://raw.githubusercontent.com/Wizmann/assets/master/wizmann-pic/20-11-28/2020-11-28_22-24-56.png" alt="">&lt;/p>
&lt;ul>
&lt;li>存储池（pool）：逻辑层，每一个pool里都包含一些放置组&lt;/li>
&lt;li>放置组（placement-group, PG)：逻辑层，一份数据会在PG当中进行灾备复制。每一个PG都对应着一系列的存储节点&lt;/li>
&lt;li>存储节点（OSD）：用以存储数据的物理节点。与PG之间形成多对多的关系。&lt;/li>
&lt;/ul>
&lt;p>一份数据在写入RADOS时，会先选中一个pool。Pool中再使用一定的hash规则，伪随机的选中某一个PG。PG会将数据写入多个OSD中。读取数据时，也是类似的规则。&lt;/p>
&lt;p>Pool是用户可见的管理数据的基本单位，用户可以对Pool进行一系列的配置（权限控制、使用SSD or HDD、使用数据拷贝 or 纠删码，etc.）。而PG与OSD对于用户是不可见的。&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/Wizmann/assets/master/wizmann-pic/20-11-28/2020-11-28_23-00-51.png" alt="">&lt;/p>
&lt;h4 id="pg的组织">PG的组织 &lt;a href="#pg%e7%9a%84%e7%bb%84%e7%bb%87" class="anchor">🔗&lt;/a>&lt;/h4>&lt;p>在一致性哈希中，我们使用节点来划分哈希值域。这种方法的问题是，如果产生了数据不平衡，我们需要重新进行划分值域来进行再平衡。这会造成大量的数据迁移。&lt;/p>
&lt;p>CRUSH采用了虚拟节点（也就是PG）将哈希值域划分成了固定的等长区域。这种方法在单条数据与物理节点之间加入了一个虚拟层。之后，再使用哈希取模的算法确定数据属于哪个PG。使得数据的迁移是以虚拟节点为单位，而不是对每一条数据都重新计算。Ceph官方的建议是，每1个OSD对应着100个PG。&lt;/p>
&lt;p>一般情况下，在规划的初期需要确定PG的数目，如果后期需要调整PG，有可能会导致大量的数据迁移，甚至需要服务暂时停止服务。&lt;/p>
&lt;h3 id="监控子集群mon与cluster-map">监控子集群（MON）与Cluster Map &lt;a href="#%e7%9b%91%e6%8e%a7%e5%ad%90%e9%9b%86%e7%be%a4mon%e4%b8%8ecluster-map" class="anchor">🔗&lt;/a>&lt;/h3>&lt;p>&lt;img src="https://raw.githubusercontent.com/Wizmann/assets/master/wizmann-pic/20-11-28/2020-11-28_22-48-10.png" alt="">&lt;/p>
&lt;p>RADOS集群中除了OSD存储节点之外，还有监控子集群（MON），用于存储系统的拓扑结构——Cluster Map。&lt;/p>
&lt;blockquote>
&lt;p>元数组管理（MDS）节点用于管理CephFS中的文件元信息，后文会有介绍。&lt;/p>&lt;/blockquote>
&lt;p>不同于传统的中心化管理节点，MON并不会对资源进行调配与调度，而仅仅是一个观测者，用以存储系统当前的拓扑与状态。&lt;/p>
&lt;p>MON与OSD、OSD与OSD之间会定时发送心跳包，检测OSD是否健康。如果某个节点失效，MON会更新内部存储的拓扑结构信息（ClusterMap），并且通过P2P协议广播出去，从而使得整个系统都有着（最终）一致的拓扑信息。&lt;/p>
&lt;h3 id="主从同步与节点自治">主从同步与节点自治 &lt;a href="#%e4%b8%bb%e4%bb%8e%e5%90%8c%e6%ad%a5%e4%b8%8e%e8%8a%82%e7%82%b9%e8%87%aa%e6%b2%bb" class="anchor">🔗&lt;/a>&lt;/h3>&lt;p>在一个PG中，会有一个主节点（Primary）和一个或多个从节点（Secondary）。主节点负责维护从节点的状态，包括数据复制（replication）、失效检测（failure detection）和失效恢复（failure recovery）。&lt;/p>
&lt;h2 id="crush---ceph皇冠上的明珠">CRUSH - Ceph皇冠上的明珠 &lt;a href="#crush---ceph%e7%9a%87%e5%86%a0%e4%b8%8a%e7%9a%84%e6%98%8e%e7%8f%a0" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>CRUSH是一个可扩展的，伪随机的数据放置算法。以去中心化方法，将PG按规则映射到相应的存储设备上。并且系统的拓扑结构发生变化时，尽可能的减少数据的迁移。&lt;/p>
&lt;h3 id="crush的优势">CRUSH的优势 &lt;a href="#crush%e7%9a%84%e4%bc%98%e5%8a%bf" class="anchor">🔗&lt;/a>&lt;/h3>&lt;p>CRUSH对于每一个数据元素使用一个伪随机算法，决定其放置的位置。所以，只要所有参与者都拥有相同的系统拓扑结构信息，那么数据的位置就是一定的。所以我们可以去掉中心节点，采用P2P的方法来进行数据的存储与检索。&lt;/p>
&lt;p>并且，由于伪随机算法只与单个PG相关，如果我们操作得当，节点数量的变化并不会引起大量的数据迁移，而是会接近理论最优值。&lt;/p>
&lt;h3 id="数据放置data-placement">数据放置（Data Placement） &lt;a href="#%e6%95%b0%e6%8d%ae%e6%94%be%e7%bd%aedata-placement" class="anchor">🔗&lt;/a>&lt;/h3>&lt;p>CRUSH的数据放置算法有很多不同的实现，这里只介绍最常用的straw算法。&lt;/p>
&lt;p>Ceph中，每一个OSD节点都有一个权值w，代表着某个节点能支持多少数据的存储与检索。一般来说，权值与节点的容量成正比。&lt;/p>
&lt;p>假设一个pool里面有n个PG，在一条新的数据写入时，我们分别会计算这n个PG的length值。&lt;/p>
&lt;p>$$ length_{i} = f(w_{i}) * hash(x) $$&lt;/p>
&lt;p>$f(w_{i})$是一个只于当前OSD节点权值有关的函数。$hash(x)$代表当前PG的哈希值。所以，PG会放置在哪个OSD上，仅与其权值相关。&lt;/p>
&lt;p>假设某个OSD节点发生变化时（新加、删除、权值变化），在此受影响节点的数据会迁移到其它的OSD节点。其它OSD节点的原有数据并不会受到影响。&lt;/p>
&lt;blockquote>
&lt;p>Ceph当中的straw算法有&lt;code>straw1&lt;/code>和&lt;code>straw2&lt;/code>。&lt;code>straw1&lt;/code>的实现采用了有缺陷f(w)函数，会导致意外的数据迁移。&lt;code>straw2&lt;/code>解决了这个问题。
详情请戳&lt;a href="https://www.spinics.net/lists/ceph-devel/msg21635.html">这里&lt;/a>&lt;/p>&lt;/blockquote>
&lt;h4 id="主从架构">主从架构 &lt;a href="#%e4%b8%bb%e4%bb%8e%e6%9e%b6%e6%9e%84" class="anchor">🔗&lt;/a>&lt;/h4>&lt;p>每个PG所包含的OSD都由CRUSH算法计算得出，并根据配置选出前r个OSD进行主从配对。列表中的第1个OSD做为主节点（Primary），其它的节点为从节点（Secondary）。&lt;/p>
&lt;p>主从节点的分配与管理由PG内部进行自治，不需要额外的外部系统进行管理。&lt;/p>
&lt;h2 id="cephfs">CephFS &lt;a href="#cephfs" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>CephFS是一个POSIX兼容的（共享）文件系统。CephFS利用文件元数据子系统（MDS）来维护目录树结构和文件和目录的元信息（owner, timestamps, inodes, etc.)等。&lt;/p>
&lt;p>MDS子系统会在内存里面维护一份Cache，对于需要持久化的信息，会使用WAL的方式写入RADOS里一个专用的Pool当中。&lt;/p>
&lt;h3 id="动态树划分dynamic-tree-partitioningdtp">动态树划分（Dynamic Tree Partitioning，DTP） &lt;a href="#%e5%8a%a8%e6%80%81%e6%a0%91%e5%88%92%e5%88%86dynamic-tree-partitioningdtp" class="anchor">🔗&lt;/a>&lt;/h3>&lt;p>CephFS的扩展性的关键之一，在于元信息子系统的扩展性。CephFS实现了动态树划分的算法，将目录树结构根据当前系统的负载，将其划分到不同的MDS节点上去。&lt;/p>
&lt;p>维护目录树结构的优势在于利用了文件系统的局部性（locality），可以方便的进行预取（prefetch）。动态的树划分，可以保证元信息可以线性增长，以保持高可扩展性。&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/Wizmann/assets/master/wizmann-pic/20-11-29/2020-11-29_18-53-09.png" alt="">&lt;/p>
&lt;h2 id="写在最后">写在最后 &lt;a href="#%e5%86%99%e5%9c%a8%e6%9c%80%e5%90%8e" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>本文基于Ceph的三篇论文综合而成（CephFS、RADOS、CRUSH）。其中加入了一些自己的看法，使其逻辑通顺，并不保证与论文的思路完全一致。&lt;/p>
&lt;p>这三篇论文并没有明确的依赖关系，换句话说，需要综合阅读，才能有比较明确的理解。&lt;/p>
&lt;p>建议在通读论文后，去学习一下&lt;a href="https://www.youtube.com/watch?v=PmLPbrf-x9g&amp;amp;ab_channel=Ceph">这个视频&lt;/a>，会对理解Ceph有很大的帮助。Youtube上面还有很多Ceph的tech talk，可以一并的了解一下。&lt;/p>
&lt;p>Ceph相关的书籍以实践居多，只推荐&lt;a href="https://www.oreilly.com/library/view/learning-ceph-/9781787127913/">Learning Ceph&lt;/a>。&lt;/p>
&lt;h2 id="参考链接">参考链接 &lt;a href="#%e5%8f%82%e8%80%83%e9%93%be%e6%8e%a5" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>&lt;a href="https://crossoverjie.top/2018/01/08/Consistent-Hash/">一致性 Hash 算法分析&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/60963885">从一致性 hash 到 ceph crush&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ceph.io/publications/">Ceph Publications&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>ZeroMQ启示录</title><link>https://wizmann.top/posts/inspiration-from-zeromq/</link><pubDate>Tue, 07 Apr 2015 10:01:34 +0000</pubDate><guid>https://wizmann.top/posts/inspiration-from-zeromq/</guid><description>&lt;h2 id="ømq是一个消息系统">ØMQ是一个消息系统 &lt;a href="#%c3%b8mq%e6%98%af%e4%b8%80%e4%b8%aa%e6%b6%88%e6%81%af%e7%b3%bb%e7%bb%9f" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>ZeroMQ是一个消息系统，也被称为“消息中间件”。它被广泛的用于经济、游戏、嵌入式等领域。&lt;/p>
&lt;h3 id="什么是消息系统">什么是消息系统 &lt;a href="#%e4%bb%80%e4%b9%88%e6%98%af%e6%b6%88%e6%81%af%e7%b3%bb%e7%bb%9f" class="anchor">🔗&lt;/a>&lt;/h3>&lt;p>打个比方，消息系统就像我们使用的IM软件一样。首先，一方决定将消息发往何处（一对一或一对多）。然后将信息打包，点击发送按钮。之后，IM系统会帮你料理剩余的事务。&lt;/p>
&lt;p>但是，它们也有很大的不同点。IM系统对于消息系统似乎太低效了一点。另外，消息系统是没有用户界面（GUI）的。在错误发生时，消息的另一端也不会有人来智能的介入处理。&lt;/p>
&lt;p>所以，我们可以这样下定义。消息系统是具有高效性和容错性的消息传递解决方案。&lt;/p>
&lt;h3 id="zeromq的起源和发展">ZeroMQ的起源和发展 &lt;a href="#zeromq%e7%9a%84%e8%b5%b7%e6%ba%90%e5%92%8c%e5%8f%91%e5%b1%95" class="anchor">🔗&lt;/a>&lt;/h3>&lt;p>ZeroMQ最先的设想是实现一个炒鸡快的用于证券交易的消息系统，所以在设计初期的关注点就是在极致的优化上。&lt;/p>
&lt;p>第一年的工作重点，在于发明性能测试的方法，和设计高效架构。&lt;/p>
&lt;p>之后，大约在第二年，工作重点转移到实现一个通用的消息系统，以应用于分布式系统，使其可以利用&lt;strong>不同的编程语言&lt;/strong>，使用&lt;strong>不同方式&lt;/strong>，来传递&lt;strong>各种模式&lt;/strong>的信息。&lt;/p>
&lt;h2 id="启示1独立应用-vs-程序库">启示1：独立应用 vs. 程序库 &lt;a href="#%e5%90%af%e7%a4%ba1%e7%8b%ac%e7%ab%8b%e5%ba%94%e7%94%a8-vs-%e7%a8%8b%e5%ba%8f%e5%ba%93" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>ZeroMQ是一个程序库，不是一个消息服务器。这样设计的主要原因是：性能。&lt;/p>
&lt;p>使用一个中间消息服务器（Broker），每一条消息都会被在网络上传递两次（Sender-&amp;gt;Broker-&amp;gt;Receiver)。这样的设计会影响时延和吞吐量。更严重的是，如果所有消息都通过中间服务器，那么这个点就会成为整个系统的瓶颈。&lt;/p>
&lt;p>使用中间消息服务器的另一个弊端，是不利于大规模部署。对于证券交易来说（ZeroMQ最初的应用场景），跨组织的消息传输是不可避免的。这样一来，中央集权式的消息传输就不在有效了。&lt;/p>
&lt;p>所以，我们缩小消息系统的粒度，使之成为一个程序库。使其更轻量，更易于部署。同样，更轻量的消息系统可以实现更复杂的拓扑结构。&lt;/p>
&lt;p>获得的启示：对于一个新项目来说，如果可能，尽量把它实现为一个程序库。将一个新库联编到原有程序中，只需要少量的人力，也提供了足够的灵活性。&lt;/p>
&lt;h2 id="启示2全局状态">启示2：全局状态 &lt;a href="#%e5%90%af%e7%a4%ba2%e5%85%a8%e5%b1%80%e7%8a%b6%e6%80%81" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>对于程序库来说，全局状态往往不能正确的工作。&lt;/p>
&lt;p>由于一个程序库可能被一个应用程序加载多次，这就不能保证只有独一无二的全局状态。&lt;/p>
&lt;p>ZeroMQ的解决方法是由库的调用者显式的维护一个“环境”，如图所示。&lt;code>libA&lt;/code>和&lt;code>libB&lt;/code>都有其独有的“环境”信息。&lt;/p>
&lt;p>&lt;img src="https://github.com/Wizmann/assets/raw/master/wizmann-pic/71080471bf8bbf4d4e186c353d6b512c" alt="Alt text">&lt;/p>
&lt;p>获得的启示：不要在程序库中使用全局状态。如果你这么做了，当库恰好需要在同一个进程中实例化两次时，它很可能会崩溃。&lt;/p>
&lt;h2 id="启示3性能">启示3：性能 &lt;a href="#%e5%90%af%e7%a4%ba3%e6%80%a7%e8%83%bd" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>&lt;img src="https://github.com/Wizmann/assets/raw/master/wizmann-pic/4ae6721a94012d877709075558562f2b" alt="Alt text">&lt;/p>
&lt;p>ZeroMQ在最初设计时，性能调优就是首要的目标。做为一个消息系统，其性能指标主要有两个：吞吐量和延时。&lt;/p>
&lt;p>但是我们怎么度量它们呢？&lt;/p>
&lt;p>如上图所示，A向B发送信息。B在6秒内接收到了5条信息，因此吞吐量为0.83消息/秒，平均时延为1.2秒。&lt;/p>
&lt;p>如果我们换一种计量方式，A向B发送消息，对于单条信息来说，其平均时延为3秒。A花费2秒，发送了所有的消息；B花费了4秒，接收到了所有的消息。所以A的吞吐量为2.5消息/秒，B的吞吐量为1.25消息/秒。这个数据与我们上面得出的数据相差甚远。&lt;/p>
&lt;p>由此，我们可以看出，使用不同的计量标准，对于我们估计系统的性能，会带来很大的不同。&lt;/p>
&lt;p>时延只有在两个节点通信时，才可能发生。所以，并不能有“某节点的时延”这种度量标准的出现。同样，我们可以对多条消息的时延进行平均，但是并不能有“一个消息流的平均时延”。&lt;/p>
&lt;p>吞吐量，与时延不同，只能在单个节点上进行度量。所以，并不能有“节点间的吞吐量”这种度量方法。&lt;/p>
&lt;p>获得的启示：深入了解你所要解决的问题。否则，你会在解决问题时会引入（错误的）假定和玄学，写出有缺陷的复杂代码。&lt;/p>
&lt;h2 id="启示4关键路径">启示4：关键路径 &lt;a href="#%e5%90%af%e7%a4%ba4%e5%85%b3%e9%94%ae%e8%b7%af%e5%be%84" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>代码中经常被调用的代码，被称为&lt;strong>关键路径&lt;/strong>。&lt;/p>
&lt;p>对于ZeroMQ来说，建立链接与内存申请都不是影响性能的最主要因素。因为ZeroMQ使用长链接进行通信，所以建立链接的开销均摊到每一条信息微乎其微。同样，ZeroMQ使用高效的内存维护机制，尽可能少的向系统直接申请内存空间。&lt;/p>
&lt;p>获得的启示：只在系统的关键路径上做优化。否则只是浪费时间。&lt;/p>
&lt;h2 id="启示5内存申请">启示5：内存申请 &lt;a href="#%e5%90%af%e7%a4%ba5%e5%86%85%e5%ad%98%e7%94%b3%e8%af%b7" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>对于一个高效的系统来说，高效的处理内存的方法往往是在内存申请与内存拷贝之间寻求一个平衡。&lt;/p>
&lt;p>对于小型数据来说，直接拷贝数据，即“深拷贝”，的开销更小。而对于大型数据来说，所谓“浅拷贝”的开销更小。&lt;/p>
&lt;p>&lt;img src="https://github.com/Wizmann/assets/raw/master/wizmann-pic/48deb1742653d61ba04f6e9591f71902" alt="Alt text">&lt;/p>
&lt;p>ZeroMQ使用透明的方式来处理两种不同的场景。并且，对于规模较大的数据，使用引用计数的策略，最大限度的复用与节省内存使用。&lt;/p>
&lt;p>获得的启示：当我们优化性能时，不要假定只有一个全局最优解。在不同的场景下，最优解的定义可能大不相同。&lt;/p>
&lt;h2 id="启示6批处理">启示6：批处理 &lt;a href="#%e5%90%af%e7%a4%ba6%e6%89%b9%e5%a4%84%e7%90%86" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>对于一个高性能消息系统来说，系统调用的绝对数量就是系统的瓶颈。这其实是一个很普遍的问题，消息在调用栈之间传递，会带来不可忽略的性能损失。所以，在构建一个高性能系统时，应该尽量避免消息在栈间的传递。&lt;/p>
&lt;p>如下图所示，对于四条消息，我们需要遍历整个网络栈四次。&lt;/p>
&lt;p>&lt;img src="https://github.com/Wizmann/assets/raw/master/wizmann-pic/b99f65135b0f0e840131c58d2cc57896" alt="Alt text">&lt;/p>
&lt;p>然而，如果我们将这些消息打包成一条消息。我们只需要遍历网络栈一次。&lt;/p>
&lt;p>&lt;img src="https://github.com/Wizmann/assets/raw/master/wizmann-pic/cd2ea1ae7a71443b3ff85ebbc7cb1c3b" alt="Alt text">&lt;/p>
&lt;p>在这里，我们的策略与TCP/IP协议中的Nagle算法类似。Nagle算法是为了充分利用带宽，而ZeroMQ的Batching策略是为了均摊网络栈的时间开销。&lt;/p>
&lt;p>具体的实现如下:&lt;/p>
&lt;ul>
&lt;li>当消息的频率没有超过网络栈的带宽时，ZeroMQ会把所有batching关掉，以CPU利用率来换取低时延。&lt;/li>
&lt;li>当消息的频率超过网线栈的带宽时，ZeroMQ会启用batching，以时延为代价来优化吞吐量。&lt;/li>
&lt;li>当消息队列中的消息过多时，ZeroMQ会采用更激进的batching策略。因为消息的堆积造成的时延增长已经不可避免，索性将更多的信息打包，这样可以更快的清空消息的积压。&lt;/li>
&lt;/ul>
&lt;p>另外，batching策略只应该被应用于顶层。在顶层采用batching之后，低层的batching就没有意义了。&lt;/p>
&lt;p>获得的启示：&lt;/p>
&lt;ul>
&lt;li>在一个异步系统中，想要获得最佳的响应时间，应该把底层的batching策略转移到顶层。&lt;/li>
&lt;li>batching只应该在新数据到来的速度超过系统带宽时才采用。&lt;/li>
&lt;/ul>
&lt;h2 id="启示7整体架构">启示7：整体架构 &lt;a href="#%e5%90%af%e7%a4%ba7%e6%95%b4%e4%bd%93%e6%9e%b6%e6%9e%84" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>&lt;img src="https://github.com/Wizmann/assets/raw/master/wizmann-pic/22f7b30fb17c9a128bbb6dd66ad27a13" alt="Alt text">&lt;/p>
&lt;p>用户利用“socket”与ZeroMQ进行交互，一个socket可以同多个peer进行交互。&lt;/p>
&lt;p>socket存在于用户线程中。而一些工作线程会处理异步的交互过程，如：从网络读取消息，将消息放入队列，接受新的连接请求等。&lt;/p>
&lt;p>session负责与ZeroMQ中的socket进行交互，engine负责网络交互。session只有一种，而engine根据使用的协议不同，可以有很多种。&lt;/p>
&lt;p>session与socket之间使用pipe进行通信，pipe被实现为线程安全的双端队列，用来在线程间传递信息。&lt;/p>
&lt;p>获得的启示：学习了整体的设计思路（笑&lt;/p>
&lt;h2 id="启示8并发模型">启示8：并发模型 &lt;a href="#%e5%90%af%e7%a4%ba8%e5%b9%b6%e5%8f%91%e6%a8%a1%e5%9e%8b" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>高效的ZeroMQ必然要利用多核的计算资源，而传统的多线程模型会引入锁、信号量等线程同步机制，会影响系统的整体性能。而使用独立的线程又会引入上下文切换的开销。&lt;/p>
&lt;p>ZeroMQ使用的并发模型是Actor，其目标是完全避免锁的使用，让所有的组件全速运行。&lt;/p>
&lt;p>每一个CPU核心只有一个worker线程，所有内部对象都是线程专有的，这样就完全避免了锁的使用。&lt;/p>
&lt;p>这样一来，许多对象都要分享有限个数的worker。所以，系统应当是全异步的。因为每一个worker的阻塞，都会阻塞其它使用worker的对象。&lt;/p>
&lt;p>获得的启示：Actor模型是极致解决性能与扩展性问题的方法。但是，如果你不是在使用ZeroMQ或Erlang，你需要手写许多相关的Test Case来测试系统的正确性和稳定性。另外，如果你无法应对模型中的复杂模块（如ZeroMQ的shutdown），请不要轻易尝试使用Actor模型。&lt;/p>
&lt;h2 id="启示9无锁算法">启示9：无锁算法 &lt;a href="#%e5%90%af%e7%a4%ba9%e6%97%a0%e9%94%81%e7%ae%97%e6%b3%95" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>无锁算法使用简单的方法进行线程间的通信，而不依赖内核级的同步原语。无锁算法的关键是CPU中的原子操作，例如compare-and-swap（CAS）操作。但是，要记住，无锁操作并不是真正的“无锁”，而是把锁操作放到了较为高效的硬件层。&lt;/p>
&lt;p>ZeroMQ使用一个无锁队列在用户线程与工作线程间进行消息传递。ZeroMQ中的无锁队列有如下特点：&lt;/p>
&lt;p>第一，每一个队列为“一写一读”。当有一对多的读写需求存在时，ZeroMQ会创建多条队列。这样的设计使得我们不用关心多线程读写带来的同步问题，有利于我们对其性能的优化。&lt;/p>
&lt;p>第二，即使无锁算法比传统的锁算法要快很多，但是其代价仍然是过高的（尤其是在CPU核心之间的通信）。所以，我们仍然依赖于“batching”算法，将昂贵的同步操作均摊到多条消息上。在从队列真正的读写操作之前，加入一次预处理（pre-write / pre-read），将消息打个包，发申通。&lt;/p>
&lt;p>&lt;img src="https://github.com/Wizmann/assets/raw/master/wizmann-pic/9d97e2979db40e413e43cf7d642d1570" alt="Alt text">&lt;/p>
&lt;p>获得的启示：无锁算法是非常精巧的，如果可能的话，尽量使用成熟的设计。如果你需要极致的性能，不要仅仅依赖于无锁算法。尽管无锁算法非常快，你仍然可以通过batching策略优化它。（另外，加钱上船也可以。）&lt;/p>
&lt;h2 id="启示10api设计">启示10：API设计 &lt;a href="#%e5%90%af%e7%a4%ba10api%e8%ae%be%e8%ae%a1" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>&lt;strong>设计API，就像设计一款产品。&lt;/strong>&lt;/p>
&lt;p>用户对于一个程序库的第一感觉来自于用户接口。ZeroMQ简化了自己的用户接口，将其由原来的“炒鸡复杂一不小心坑死你的企业级消息框架”变为了“想发消息调用下就OK”的极易上手的入门级产品。&lt;/p>
&lt;p>另外一个重要的方面，ZeroMQ使用了广为使用的BSD Sockets API。这样做的优点是：&lt;/p>
&lt;ul>
&lt;li>这是一个大家都熟知的API，学习曲线相当平缓&lt;/li>
&lt;li>使ZeroMQ与现有的技术连接起来，有利于复用已用的框架与设计&lt;/li>
&lt;li>最重要的是，使用一个成熟与久经考验的框架，可以避免踩前人踩过的坑、&lt;/li>
&lt;/ul>
&lt;p>获得的启示：除了代码复用之外，我们还可以以一种更一般的方法，复用成熟的技术。当你设计一个新产品时，借鉴一下类似的产品（腾讯！）。不要犯“在这里还没有被发明”（Not Invented Here）综合症。复用一切合适的想法、API、框架抽象。允许用户使用已有的知识，同时也可以让我们规避未知的风险。&lt;/p>
&lt;h2 id="启示11消息模式">启示11：消息模式 &lt;a href="#%e5%90%af%e7%a4%ba11%e6%b6%88%e6%81%af%e6%a8%a1%e5%bc%8f" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>ZeroMQ的设计思路是&lt;strong>专注于一个领域，把它做到最好&lt;/strong>。因为，大而全的产品只能给领域专家来使用，而小而精的产品的受众则是任何受过训练的程序员。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>s &lt;span style="color:#f92672">=&lt;/span> socket (REQ)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>s.connect (&lt;span style="color:#e6db74">&amp;#34;tcp://192.168.0.111:5555&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>s.send (&lt;span style="color:#e6db74">&amp;#34;Hello World!&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>reply &lt;span style="color:#f92672">=&lt;/span> s.recv ()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>当我们要给用户提供更一般性的解决方案时，一个技术栈，栈的每一层可以有不同的实现，从而适应不同人群的需要。&lt;/p>
&lt;p>这和Internet栈的设计思路非常相似：TCP可以解决基于链接的、可靠的数据流传输，UDP可以解决不可靠的数据包传输，SCTP可以解决多用户数据流传输问题等等。&lt;/p>
&lt;p>这样一来，所有的解决方案都是正交的，我们可以利用其中好的设计，也可以没有额外代价的抛弃不好的设计。&lt;/p>
&lt;p>获得的启示：当解决一个复杂且多面化的问题时，单个通用型的解决方案可能并不是最好的方式。相反，我们可以把问题的领域想象成一个抽象层，并基于这个层次提供多个实现，每种实现只致力于解决一种定义良好的情况。&lt;/p>
&lt;p>当我们这么做时，确定问题的粒度非常重要。如果粒度过细，软件的一般性就会受到限制。如果粒度过粗，那么产品就会变得非常复杂，给用户带来模糊和混乱的感觉。&lt;/p>
&lt;h2 id="后记">后记 &lt;a href="#%e5%90%8e%e8%ae%b0" class="anchor">🔗&lt;/a>&lt;/h2>&lt;ul>
&lt;li>原文链接：http://www.aosabook.org/en/zeromq.html&lt;/li>
&lt;li>中文翻译：http://www.ituring.com.cn/article/4669&lt;/li>
&lt;/ul>
&lt;p>本文中借鉴了中文翻译的部分词句，对此表示感谢。&lt;/p></description></item></channel></rss>